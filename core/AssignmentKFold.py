from .AssignmentBaseModel import AssignmentBaseModel
from .DataLoader import DataLoader, DataPreprocessor

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
import threading
import copy


class AssignmentKFold:
    """
    AssignmentKFold is a class that facilitates the training, evaluation, and analysis of machine learning models
    using K-Fold cross-validation. It supports multithreading for efficient processing and provides various methods
    to train models, compute sample weights, evaluate accuracy, and visualize results.
    Attributes:
        model_type (type[AssignmentBaseModel]): The type of model to be used for training and evaluation.
        feature_index_dict (dict): A dictionary mapping feature names to their indices.
        max_jets (int): The maximum number of jets in the dataset.
        max_leptons (int): The maximum number of leptons in the dataset.
        n_data_sets (int): The total number of datasets (n_folds * n_splits).
        random_state (int): The random seed for reproducibility.
        model_list (list[AssignmentBaseModel]): A list of models for each fold.
        k_fold (list): The K-Fold split data generated by the data processor.
    Methods:
        __init__(model_type, data_processor, n_folds=5, n_splits=1, random_state=42):
            Initializes the AssignmentKFold object and prepares the models and data splits.
        compute_sample_weights(**kwargs):
            Computes sample weights for each model in the K-Fold split.
        build_models(**kwargs):
            Builds the models for each fold using the provided parameters.
        compile_models(**kwargs):
            Compiles the models for each fold using the provided parameters.
        train_models(epochs=1, batch_size=1028, **kwargs):
            Trains the models for each fold using the specified number of epochs and batch size.
        print_model_summary():
            Prints the summary of the first model in the K-Fold split.
        enhance_region(variable, data_type, low_cut=None, high_cut=None, factor=1):
            Enhances a specific region of the data for each model in the K-Fold split.
        evaluate_accuracy():
            Evaluates the accuracy of each model and returns the mean and standard error for lepton 1, lepton 2, and combined accuracy.
        accuracy_vs_feature(feature_name, data_type="non_training", bins=50, xlims=None):
            Plots the accuracy of the models as a function of a specific feature.
        plot_permutation_importance(file_name=None):
            Plots the permutation importance of features for lepton 1, lepton 2, and combined accuracy.
        plot_confusion_matrix(data=None, labels=None, exclusive=True):
            Plots the confusion matrix for lepton 1 and lepton 2 across the K-Fold split.
        save_model(file_path="model.keras"):
            Saves the models for each fold to the specified file path.
        load_model(file_path="model.keras"):
            Loads the models for each fold from the specified file path.
        plot_history():
            Plots the training history for each model in the K-Fold split.
        duplicate_jets():
            Computes and returns the mean and standard error of duplicate jet numbers across the K-Fold split.
        plot_feature_variance(feature_name, data_type="non_training", bins=50, xlims=None):
            Plots the variance of a specific feature across the K-Fold split.
    """

    def __init__(
        self,
        model_type: type[AssignmentBaseModel],
        data_processor: DataPreprocessor,
        n_folds=5,
        n_splits=1,
        random_state=42,
    ):
        """
        Initializes the AssignmentKFold class.
        Args:
            model_type (type[AssignmentBaseModel]): The type of the model to be used for training.
            data_processor (DataPreprocessor): An instance of DataPreprocessor to handle data preparation.
            n_folds (int, optional): The number of folds for k-fold cross-validation. Defaults to 5.
            n_splits (int, optional): The number of splits for each fold. Defaults to 1.
            random_state (int, optional): The random seed for reproducibility. Defaults to 42.
        Attributes:
            model_type (type[AssignmentBaseModel]): The type of the model to be used for training.
            feature_index_dict (dict): A dictionary mapping feature names to their indices.
            max_jets (int): The maximum number of jets in the dataset.
            max_leptons (int): The maximum number of leptons in the dataset.
            n_data_sets (int): The total number of datasets (n_folds * n_splits).
            random_state (int): The random seed for reproducibility.
            model_list (list[AssignmentBaseModel]): A list of model instances for each dataset.
            k_fold (list): A list of k-fold datasets created by the data processor.
        Notes:
            - This method initializes the k-fold datasets and creates a list of model instances.
            - Data loading for each model is performed in parallel using threads.
        """

        self.model_type = model_type
        self.feature_index_dict = data_processor.feature_index_dict
        self.max_jets = data_processor.max_jets
        self.max_leptons = data_processor.max_leptons
        self.n_data_sets = n_folds * n_splits
        self.random_state = random_state
        self.model_list: list[AssignmentBaseModel] = []
        self.k_fold = data_processor.create_k_folds(
            n_folds=n_folds, n_splits=n_splits, random_state=random_state
        )
        for i in range(self.n_data_sets):
            self.model_list.append(model_type(data_processor))

        def load_data_thread(model: AssignmentBaseModel, data):
            model.load_data(*data)

        threads = []
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=load_data_thread, args=(self.model_list[i], self.k_fold[i])
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    def compute_sample_weights(self, **kwargs):
        """
        Compute sample weights for each model in the model list using multithreading.
        This method spawns a separate thread for each model in `self.model_list` to compute
        sample weights concurrently. The computation for each model is performed by calling
        its `compute_sample_weights` method with the provided keyword arguments.
        Args:
            **kwargs: Arbitrary keyword arguments to be passed to the `compute_sample_weights`
                  method of each model.
        Note:
            - The `compute_sample_weights` method of each model must accept an `alpha` parameter
              as part of the keyword arguments.
            - This method ensures that all threads complete their execution before returning.
        """

        def compute_weights_thread(model: AssignmentBaseModel, alpha):
            model.compute_sample_weights(alpha=alpha)

        threads = []
        for model in self.model_list:
            thread = threading.Thread(
                target=compute_weights_thread, args=(model,), kwargs=kwargs
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    def build_models(self, **kwargs):
        """
        Builds models in parallel using threads.
        This method iterates over a list of models and builds each model in a separate thread.
        The `build_model` method of each model is called with the provided keyword arguments.
        Args:
            **kwargs: Arbitrary keyword arguments to be passed to the `build_model` method
                      of each model in the `model_list`.
        Notes:
            - The method ensures that all threads complete their execution by calling `join`
              on each thread after starting them.
            - A deep copy of the keyword arguments is passed to each model's `build_model`
              method to avoid unintended side effects.
        """

        def build_model_thread(model: AssignmentBaseModel, **kwargs):
            model.build_model(**copy.deepcopy(kwargs))

        threads = []
        for model in self.model_list:
            thread = threading.Thread(
                target=build_model_thread, args=(model,), kwargs=kwargs
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    def compile_models(self, **kwargs):
        """
        Compiles all models in the `model_list` using multithreading.
        This method iterates over the list of models (`self.model_list`) and compiles each model
        in a separate thread. The compilation process for each model is handled by the
        `compile_model` method of the model, with the provided keyword arguments.
        Args:
            **kwargs: Arbitrary keyword arguments that are passed to the `compile_model` method
                  of each model.
        Notes:
            - The method uses Python's `threading` module to compile models concurrently.
            - Each thread is joined to ensure that all models are compiled before the method exits.
        """

        def compile_model_thread(model, **kwargs):
            model.compile_model(**copy.deepcopy(kwargs))

        threads = []
        for model in self.model_list:
            thread = threading.Thread(
                target=compile_model_thread, args=(model,), kwargs=kwargs
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    def train_models(self, epochs=1, batch_size=1028, **kwargs):
        """
        Trains multiple models in parallel using threading.
        Args:
            epochs (int, optional): The number of epochs to train each model. Defaults to 1.
            batch_size (int, optional): The batch size to use for training each model. Defaults to 1028.
            **kwargs: Additional keyword arguments to pass to the `train_model` method of each model.
        Notes:
            - Each model in `self.model_list` is trained in a separate thread.
            - The `train_model` method of each model is called with the specified `epochs`, `batch_size`,
              and any additional keyword arguments provided.
            - The method waits for all threads to complete before returning.
        """

        def train_model_thread(
            model: AssignmentBaseModel, epochs, batch_size, **kwargs
        ):
            model.train_model(
                epochs=epochs, batch_size=batch_size, **copy.deepcopy(kwargs)
            )

        threads = []
        for model in self.model_list:
            thread = threading.Thread(
                target=train_model_thread,
                args=(model, epochs, batch_size),
                kwargs=kwargs,
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

    def print_model_summary(self):
        """
        Prints the summary of the first model in the model list.
        This method calls the `summary` method of the first model in `self.model_list`.
        Notes:
            - This method is useful for quickly checking the architecture and parameters of the model.
        """
        self.model_list[0].summary()

    def enhance_region(
        self, variable, data_type, low_cut=None, high_cut=None, factor=1
    ):
        """
        Enhances a specific region of a dataset by applying a scaling factor.
        Parameters:
            variable (str): The name of the variable to enhance.
            data_type (str): The type of data to be processed (e.g., training, testing).
            low_cut (float, optional): The lower bound of the region to enhance. Defaults to None.
            high_cut (float, optional): The upper bound of the region to enhance. Defaults to None.
            factor (float, optional): The scaling factor to apply to the specified region. Defaults to 1.
        Returns:
            None
        """

        for i in range(self.n_data_sets):
            self.model_list[i].enhance_region(
                variable, data_type, low_cut, high_cut, factor
            )

    def evaluate_accuracy(self):
        """
        Evaluates the accuracy of the model for multiple datasets using multithreading.
        This method calculates the mean and standard error of the accuracy for three metrics:
        - lep_1_accuracy
        - lep_2_accuracy
        - combined_accuracy
        Each dataset's accuracy is evaluated in a separate thread to improve performance.
        Returns:
            tuple: A tuple containing the following values:
            - lep_1_accuracy_mean (float): Mean accuracy for lep_1 across all datasets.
            - lep_1_accuracy_err (float): Standard error of the mean for lep_1 accuracy.
            - lep_2_accuracy_mean (float): Mean accuracy for lep_2 across all datasets.
            - lep_2_accuracy_err (float): Standard error of the mean for lep_2 accuracy.
            - combined_accuracy_mean (float): Mean combined accuracy across all datasets.
            - combined_accuracy_err (float): Standard error of the mean for combined accuracy.
        """

        lep_1_accuracy = np.zeros(self.n_data_sets)
        lep_2_accuracy = np.zeros(self.n_data_sets)
        combined_accuracy = np.zeros(self.n_data_sets)

        def evaluate_accuracy_thread(
            model: AssignmentBaseModel, index, lep_1_acc, lep_2_acc, combined_acc
        ):
            lep_1_acc[index], lep_2_acc[index], combined_acc[index] = (
                model.evaluate_accuracy()
            )

        threads = []
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=evaluate_accuracy_thread,
                args=(
                    self.model_list[i],
                    i,
                    lep_1_accuracy,
                    lep_2_accuracy,
                    combined_accuracy,
                ),
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        lep_1_accuracy_mean = np.mean(lep_1_accuracy)
        lep_2_accuracy_mean = np.mean(lep_2_accuracy)
        combined_accuracy_mean = np.mean(combined_accuracy)
        lep_1_accuracy_err = np.std(lep_1_accuracy) / np.sqrt(self.n_data_sets)
        lep_2_accuracy_err = np.std(lep_2_accuracy) / np.sqrt(self.n_data_sets)
        combined_accuracy_err = np.std(combined_accuracy) / np.sqrt(self.n_data_sets)
        return (
            lep_1_accuracy_mean,
            lep_1_accuracy_err,
            lep_2_accuracy_mean,
            lep_2_accuracy_err,
            combined_accuracy_mean,
            combined_accuracy_err,
        )

    def accuracy_vs_feature(
        self, feature_name, data_type="non_training", bins=50, xlims=None
    ):
        def accuracy_vs_feature(
            self, feature_name, data_type="non_training", bins=50, xlims=None
        ):
            """
            Plots the accuracy of the model as a function of a specified feature,
            with the option to bin the feature values and calculate accuracy within each bin.
            Args:
                feature_name (str): The name of the feature to analyze.
                data_type (str, optional): The type of data to use. Must be one of
                    'jet', 'lepton', 'non_training', or 'global'. Defaults to "non_training".
                bins (int, optional): The number of bins to divide the feature values into. Defaults to 50.
                xlims (tuple, optional): The x-axis limits for the plot as a tuple (min, max). Defaults to None.
            Raises:
                ValueError: If the specified data_type is not found in the feature index dictionary.
                ValueError: If the specified feature_name is not found in the features of the given data_type.
            Returns:
                tuple: A tuple containing:
                    - fig (matplotlib.figure.Figure): The matplotlib figure object for the plot.
                    - ax (matplotlib.axes.Axes): The matplotlib axes object for the plot.
            Notes:
                - This method uses threading to compute binned accuracy for multiple datasets in parallel.
                - The accuracy is averaged across all datasets, and the standard error is calculated.
                - A twin y-axis is used to display the feature count histogram alongside the accuracy plot.
            """

        if data_type not in self.feature_index_dict:
            raise ValueError(
                f"Data type {data_type} not found. Use 'jet', 'lepton', 'non_training', or 'global'."
            )
        if feature_name not in self.feature_index_dict[data_type]:
            raise ValueError(
                f"Feature {feature_name} not found in {data_type} features."
            )

        def compute_binned_accuracy_thread(
            model,
            index,
            feature_name,
            data_type,
            bins,
            xlims,
            results,
            feature_bins,
            feature_hist,
        ):
            results[index], feature_bins[index], feature_hist[index] = (
                model.get_binned_accuracy(
                    feature_name,
                    data_type=data_type,
                    bins=bins,
                    xlims=xlims,
                )
            )

        threads = []
        binned_accuracy_combined = [None] * self.n_data_sets
        feature_bins = [None] * self.n_data_sets
        feature_hist = [None] * self.n_data_sets
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=compute_binned_accuracy_thread,
                args=(
                    self.model_list[i],
                    i,
                    feature_name,
                    data_type,
                    bins,
                    xlims,
                    binned_accuracy_combined,
                    feature_bins,
                    feature_hist,
                ),
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        binned_accuracy_combined = np.array(binned_accuracy_combined)
        feature_bins = feature_bins[0]
        feature_hist = feature_hist[0]

        binned_accuracy_combined = np.mean(binned_accuracy_combined, axis=0)
        binned_accuracy_combined_err = np.std(
            binned_accuracy_combined, axis=0
        ) / np.sqrt(self.n_data_sets)
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        centers = (feature_bins[:-1] + feature_bins[1:]) / 2
        ax_twin = ax.twinx()
        ax_twin.set_ylabel("Feature Count", color="tab:orange")
        ax_twin.bar(
            centers,
            feature_hist,
            width=np.diff(feature_bins),
            alpha=0.3,
            color="tab:orange",
        )
        ax_twin.tick_params(axis="y", labelcolor="tab:orange")
        ax.set_xlabel(feature_name)
        ax.set_ylabel("Accuracy")
        ax.tick_params(axis="y")
        ax.errorbar(
            centers,
            binned_accuracy_combined,
            yerr=binned_accuracy_combined_err,
            label=f"{self.model_type.__name__}",
            fmt="o",
            capsize=2,
        )
        ax.set_xlabel(feature_name)
        ax.set_ylabel("Accuracy")
        ax.set_xlim(xlims)
        ax.set_ylim(0, 1.1)
        ax.legend()
        fig.tight_layout()
        return fig, ax

    def plot_permutation_importance(self, file_name=None):
        """
        Plots the permutation importance scores for lepton 1, lepton 2, and their combined accuracy
        across multiple datasets using multithreading for parallel computation.
        Args:
            file_name (str, optional): The name of the file to save the plot. If None, the plot is not saved.
        Returns:
            tuple: A tuple containing the matplotlib figure and axes objects (fig, ax).
        This method computes permutation importance scores for each dataset in `self.model_list` using
        a separate thread for each computation. The importance scores are averaged across datasets,
        and their standard errors are calculated. The results are visualized as bar plots for lepton 1,
        lepton 2, and their combined accuracy.
        Steps:
            1. Initializes lists to store importance scores for each dataset.
            2. Defines a helper function `compute_importance_thread` to compute importance scores
               for a single dataset in a thread-safe manner.
            3. Creates and starts threads for parallel computation of importance scores.
            4. Joins all threads to ensure computations are complete.
            5. Computes mean and standard error of importance scores across datasets.
            6. Plots the results as bar charts with error bars for each category (lepton 1, lepton 2, combined).
            7. Returns the figure and axes objects for further customization or saving.
        Note:
            - The method assumes that `self.model_list` contains models with a `compute_permutation_importance`
              method that returns dictionaries with "mean" keys for lepton 1, lepton 2, and combined scores.
            - The method uses pandas for data manipulation and matplotlib for plotting.
            - The number of datasets is determined by `self.n_data_sets`.
        """

        importance_scores_lep_1 = [None] * self.n_data_sets
        importance_scores_lep_2 = [None] * self.n_data_sets
        importance_scores_combined = [None] * self.n_data_sets

        def compute_importance_thread(
            model: AssignmentBaseModel,
            index,
            results_lep_1,
            results_lep_2,
            results_combined,
        ):
            lep_1, lep_2, combined = model.compute_permutation_importance(
                shuffle_number=1
            )
            results_lep_1[index] = lep_1["mean"]
            results_lep_2[index] = lep_2["mean"]
            results_combined[index] = combined["mean"]

        threads = []
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=compute_importance_thread,
                args=(
                    self.model_list[i],
                    i,
                    importance_scores_lep_1,
                    importance_scores_lep_2,
                    importance_scores_combined,
                ),
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        importance_scores_lep_1_mean = pd.concat(importance_scores_lep_1, axis=1).mean(
            axis=1
        )
        importance_scores_lep_2_mean = pd.concat(importance_scores_lep_2, axis=1).mean(
            axis=1
        )
        importance_scores_combined_mean = pd.concat(
            importance_scores_combined, axis=1
        ).mean(axis=1)

        importance_scores_lep_1_err = pd.concat(importance_scores_lep_1, axis=1).std(
            axis=1
        ) / np.sqrt(self.n_data_sets)
        importance_scores_lep_2_err = pd.concat(importance_scores_lep_2, axis=1).std(
            axis=1
        ) / np.sqrt(self.n_data_sets)
        importance_scores_combined_err = pd.concat(
            importance_scores_combined, axis=1
        ).std(axis=1) / np.sqrt(self.n_data_sets)

        fig, ax = plt.subplots(1, 3, figsize=(15, 5))
        importance_scores_lep_1_mean = importance_scores_lep_1_mean.sort_values(
            ascending=False
        )
        importance_scores_lep_2_mean = importance_scores_lep_2_mean.sort_values(
            ascending=False
        )
        importance_scores_combined_mean = importance_scores_combined_mean.sort_values(
            ascending=False
        )
        importance_scores_lep_1_mean.plot(
            kind="bar",
            yerr=importance_scores_lep_1_err,
            ax=ax[0],
            color="blue",
            alpha=0.7,
        )
        importance_scores_lep_2_mean.plot(
            kind="bar",
            yerr=importance_scores_lep_2_err,
            ax=ax[1],
            color="orange",
            alpha=0.7,
        )
        importance_scores_combined_mean.plot(
            kind="bar",
            yerr=importance_scores_combined_err,
            ax=ax[2],
            color="green",
            alpha=0.7,
        )
        ax[0].set_title("Lepton 1 Accuracy")
        ax[1].set_title("Lepton 2 Accuracy")
        ax[2].set_title("Combined Accuracy")
        ax[0].set_ylabel("Importance Score")
        ax[1].set_ylabel("Importance Score")
        ax[2].set_ylabel("Importance Score")
        fig.tight_layout()
        return fig, ax

    def plot_confusion_matrix(self, data=None, labels=None, exclusive=True):
        def plot_confusion_matrix(self, data=None, labels=None, exclusive=True):
            """
            Plots the confusion matrices for two leptons (Lepton 1 and Lepton 2)
            using the models in the dataset. The function computes the mean and
            standard deviation of the confusion matrices across multiple datasets
            and visualizes them using heatmaps.
            Args:
                data (optional): The input data to be used for generating the
                    confusion matrices. Defaults to None.
                labels (optional): The true labels corresponding to the input data.
                    Defaults to None.
                exclusive (bool, optional): If True, computes the confusion matrix
                    exclusively for the given data and labels. Defaults to True.
            Returns:
                tuple: A tuple containing:
                    - fig (matplotlib.figure.Figure): The figure object containing
                      the confusion matrix plots.
                    - ax (numpy.ndarray): An array of axes objects corresponding to
                      the subplots for the confusion matrices.
            Notes:
                - This function uses multithreading to compute confusion matrices
                  for each dataset in parallel.
                - The mean and standard deviation of the confusion matrices are
                  computed across all datasets.
                - The standard deviation values are displayed as red text on the
                  heatmaps.
                - The heatmaps are generated using the seaborn library.
            """

        confusion_matrices_lep_1 = [None] * self.n_data_sets
        confusion_matrices_lep_2 = [None] * self.n_data_sets
        max_jets = self.max_jets

        def get_confusion_matrix_thread(
            model: AssignmentBaseModel, index, exclusive, results_lep_1, results_lep_2
        ):
            confusion_matrix_lep_1, confusion_matrix_lep_2 = model.get_confusion_matrix(
                data=data, labels=labels, exclusive=exclusive
            )
            results_lep_1[index] = confusion_matrix_lep_1
            results_lep_2[index] = confusion_matrix_lep_2

        threads = []
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=get_confusion_matrix_thread,
                args=(
                    self.model_list[i],
                    i,
                    exclusive,
                    confusion_matrices_lep_1,
                    confusion_matrices_lep_2,
                ),
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()
        mean_confusion_lep_1 = np.mean(confusion_matrices_lep_1, axis=0)
        mean_confusion_lep_2 = np.mean(confusion_matrices_lep_2, axis=0)
        std_confusion_lep_1 = np.std(confusion_matrices_lep_1, axis=0) / np.sqrt(
            self.n_data_sets
        )
        std_confusion_lep_2 = np.std(confusion_matrices_lep_2, axis=0) / np.sqrt(
            self.n_data_sets
        )
        fig, ax = plt.subplots(1, 2, figsize=(12, 6))
        sns.heatmap(
            mean_confusion_lep_1,
            annot=True,
            fmt=".2f",
            cmap="Blues",
            cbar=False,
            ax=ax[0],
        )
        sns.heatmap(
            mean_confusion_lep_2,
            annot=True,
            fmt=".2f",
            cmap="Blues",
            cbar=False,
            ax=ax[1],
        )
        for i in range(max_jets):
            for j in range(max_jets):
                ax[0].text(
                    j + 0.5 + 0.3,
                    i + 0.5,
                    f"±{std_confusion_lep_1[i, j]:.2f}",
                    color="red",
                    ha="center",
                    va="center",
                    fontsize=8,
                )
                ax[1].text(
                    j + 0.5 + 0.3,
                    i + 0.5,
                    f"±{std_confusion_lep_2[i, j]:.2f}",
                    color="red",
                    ha="center",
                    va="center",
                    fontsize=8,
                )
        ax[0].set_title("Confusion Matrix for Lepton 1 (Bootstrap)")
        ax[1].set_title("Confusion Matrix for Lepton 2 (Bootstrap)")
        ax[0].set_xlabel("Predicted Label")
        ax[1].set_xlabel("Predicted Label")
        ax[0].set_ylabel("True Label")
        ax[1].set_ylabel("True Label")
        return fig, ax

    def save_model(self, file_path="model.keras"):
        """
        Saves the models in the model list to separate files using multithreading.
        This method saves each model in `self.model_list` to a file. The file names
        are generated by appending an index to the base file name provided in the
        `file_path` argument. The saving process is performed in parallel using threads.
        Args:
            file_path (str): The base file path where the models will be saved.
                     The default is "model.keras". Each model will be saved
                     with a modified file name, e.g., "model_0.keras", "model_1.keras", etc.
        Raises:
            Any exceptions raised during the model saving process will propagate.
        Example:
            If `self.n_data_sets` is 3 and `file_path` is "model.keras", the models
            will be saved as "model_0.keras", "model_1.keras", and "model_2.keras".
        Note:
            This method uses threading to save models concurrently. Ensure that the
            models in `self.model_list` are thread-safe for saving.
        """

        def save_model_thread(model, file_path):
            model.save_model(file_path)

        threads = []
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=save_model_thread,
                args=(self.model_list[i], file_path.replace(".keras", f"_{i}.keras")),
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()
        print(f"Models saved to {file_path}.")

    def load_model(self, file_path="model.keras"):
        """
        Loads pre-trained models from specified file paths and assigns them to the model list.
        This method iterates over the number of datasets (`self.n_data_sets`) and loads
        individual model files by appending an index to the base file name. Each model
        is loaded into the corresponding position in `self.model_list`.
        Args:
            file_path (str): The base file path for the model files. Defaults to "model.keras".
                     The method appends an index (e.g., "_0", "_1") before the file
                     extension for each dataset.
        Prints:
            Logs the file paths being loaded and confirms when all models are loaded.
        """

        for i in range(self.n_data_sets):
            file_path_i = file_path.replace(".keras", f"_{i}.keras")
            print("Loading model from", file_path_i)
            self.model_list[i].load_model(file_path_i)
        print(f"Models loaded from {file_path}.")

    def plot_history(self):
        """
        Plots the training history for each model in the list of models.
        This method iterates over all datasets and calls the `plot_history`
        method of each model in the `model_list`. It collects the resulting
        figures and axes for each model and returns them as lists.
        Returns:
            tuple: A tuple containing two lists:
                - fig (list): A list of matplotlib figure objects, one for each model.
                - ax (list): A list of matplotlib axes objects, one for each model.
        """

        fig, ax = [], []
        for i in range(self.n_data_sets):
            fig_i, ax_i = self.model_list[i].plot_history()
            fig.append(fig_i)
            ax.append(ax_i)
        return fig, ax

    def duplicate_jets(self):
        """
        Computes the mean and standard error of duplicate jet numbers across multiple datasets.
        This method uses multithreading to calculate the number of duplicate jets for each model in `self.model_list`.
        Each model's `duplicate_jets` method is called in a separate thread, and the results are collected.
        Returns:
            tuple: A tuple containing:
                - mean_duplicate_jet_numbers (numpy.ndarray): The mean number of duplicate jets across all datasets.
                - std_duplicate_jet_numbers (numpy.ndarray): The standard error of the mean number  of duplicate jets.
        Notes:
            - The method initializes a list to store the duplicate jet numbers for each dataset.
            - A helper function `duplicate_jets_thread` is defined to call the `duplicate_jets` method of each model.

        """
        duplicate_jet_numbers = [None] * self.n_data_sets

        def duplicate_jets_thread(model, index, results):
            results[index] = model.duplicate_jets()

        threads = []
        for i in range(self.n_data_sets):
            thread = threading.Thread(
                target=duplicate_jets_thread,
                args=(self.model_list[i], i, duplicate_jet_numbers),
            )
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        duplicate_jet_numbers = np.array(duplicate_jet_numbers)
        return np.mean(duplicate_jet_numbers, axis=0), np.std(
            duplicate_jet_numbers, axis=0
        ) / np.sqrt(self.n_data_sets)

    def plot_feature_variance(
        self, feature_name, data_type="non_training", bins=50, xlims=None
    ):
        def plot_feature_variance(
            self, feature_name, data_type="non_training", bins=50, xlims=None
        ):
            """
            Plots the variance of a specific feature across multiple K-Fold datasets.
            This method visualizes the range, mean, and distribution of a given feature
            across all K-Fold datasets. It uses histograms to compute the feature counts
            and displays the range (min to max) and mean of the feature counts for each bin.
            Parameters:
            -----------
            feature_name : str
                The name of the feature to analyze and plot.
            data_type : str, optional
                The type of data to use for the analysis. Must be one of 'jet', 'lepton',
                'non_training', or 'global'. Default is "non_training".
            bins : int, optional
                The number of bins to use for the histogram. Default is 50.
            xlims : tuple or None, optional
                The range of values (min, max) to consider for the histogram. If None,
                the range is determined automatically. Default is None.
            Returns:
            --------
            fig : matplotlib.figure.Figure
                The matplotlib figure object containing the plot.
            ax : matplotlib.axes._subplots.AxesSubplot
                The matplotlib axes object containing the plot.
            Raises:
            -------
            ValueError
                If the specified `data_type` is not found in the feature index dictionary.
            ValueError
                If the specified `feature_name` is not found in the features of the given `data_type`.
            Notes:
            ------
            - The method assumes that `self.model_list` contains models with `X_test` data
              and a `feature_index_dict` mapping feature names to their indices.
            - The plot includes a bar chart showing the range of feature counts across K-Folds
              and a line plot indicating the mean feature count for each bin.
            """

        if data_type not in self.feature_index_dict:
            raise ValueError(
                f"Data type {data_type} not found. Use 'jet', 'lepton', 'non_training', or 'global'."
            )
        if feature_name not in self.feature_index_dict[data_type]:
            raise ValueError(
                f"Feature {feature_name} not found in {data_type} features."
            )
        _, hist_bins = np.histogram(
            np.concatenate(
                [
                    self.model_list[i].X_test[data_type][
                        :,
                        self.model_list[i].feature_index_dict[data_type][feature_name],
                    ]
                    for i in range(self.n_data_sets)
                ]
            ),
            bins=bins,
            range=xlims,
        )
        feature_histos = np.zeros((self.n_data_sets, bins))
        for i in range(self.n_data_sets):
            feature_histos[i], _ = np.histogram(
                self.model_list[i].X_test[data_type][
                    :, self.model_list[i].feature_index_dict[data_type][feature_name]
                ],
                bins=hist_bins,
            )
        feature_histos_min = np.min(feature_histos, axis=0)
        feature_histos_max = np.max(feature_histos, axis=0)
        feature_histos_mean = np.mean(feature_histos, axis=0)
        fig, ax = plt.subplots(figsize=(10, 5))
        centers = (hist_bins[:-1] + hist_bins[1:]) / 2
        ax.bar(
            centers,
            feature_histos_max - feature_histos_min,
            bottom=feature_histos_min,
            width=np.diff(hist_bins),
            alpha=0.5,
            color="orange",
            label="Feature Count Range",
        )
        for i in range(bins):
            ax.plot(
                [hist_bins[i], hist_bins[i + 1]],
                [feature_histos_mean[i], feature_histos_mean[i]],
                color="black",
            )
        ax.set_xlabel(feature_name)
        ax.set_ylabel("Feature Count")
        ax.set_title("Feature Variance Across K-Folds")
        fig.tight_layout()
        return fig, ax

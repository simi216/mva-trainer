{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 10:13:31.724460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764148411.746806 3708887 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764148411.754300 3708887 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764148411.772574 3708887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764148411.772592 3708887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764148411.772595 3708887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764148411.772597 3708887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-26 10:13:31.777730: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from core.DataLoader import (\n",
    "    DataPreprocessor,\n",
    "    DataConfig,\n",
    "    LoadConfig,\n",
    "    get_load_config_from_yaml,\n",
    ")\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "MAX_JETS = 6\n",
    "PLOTS_DIR = f\"plots/compare_model_performance/\"\n",
    "CONFIG_PATH = \"../config/workspace_config_HLF.yaml\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "load_config = get_load_config_from_yaml(CONFIG_PATH)\n",
    "\n",
    "DataProcessor = DataPreprocessor(load_config)\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "data_config = DataProcessor.load_from_npz(data_config[\"data_path\"][\"toponium\"],max_events=200000)\n",
    "X_train, y_train, X_val, y_val = DataProcessor.split_data(test_size=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6588d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureConcatTransformer is designed for classification tasks; regression targets will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764148482.271050 3708887 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15511 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:65:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from models/toponium_transformer_HLF/model.keras\n",
      "Training history loaded from models/toponium_transformer_HLF/model_history.npz\n",
      "FeatureConcatTransformer is designed for classification tasks; regression targets will be ignored.\n",
      "Model loaded from models/assignment_transformer_HLF/model.keras\n",
      "Training history loaded from models/assignment_transformer_HLF/model_history.npz\n",
      "FeatureConcatTransformer is designed for classification tasks; regression targets will be ignored.\n",
      "Model loaded from models/mixed_model/model.keras\n",
      "WARNING: No training history found at models/mixed_model/model_history.npz\n"
     ]
    }
   ],
   "source": [
    "import core.assignment_models as AssignmentModels\n",
    "import core.evaluation as Evaluation\n",
    "from core.reconstruction import GroundTruthReconstructor\n",
    "\n",
    "reload(Evaluation)\n",
    "reload(AssignmentModels)\n",
    "\n",
    "ToponiumTransformer = AssignmentModels.FeatureConcatTransformer(data_config, name=\"ToponiumTransformer\")\n",
    "MODEL_DIR = f\"models/toponium_transformer_HLF/\"\n",
    "ToponiumTransformer.load_model(MODEL_DIR + \"model.keras\")\n",
    "\n",
    "Transformer = AssignmentModels.FeatureConcatTransformer(data_config, name=\"Transformer\")\n",
    "MODEL_DIR = f\"models/assignment_transformer_HLF/\"\n",
    "Transformer.load_model(MODEL_DIR + \"model.keras\")\n",
    "\n",
    "MixedTransformer = AssignmentModels.FeatureConcatTransformer(data_config, name=\"ToponiumInfusedTransformer\")\n",
    "MODEL_DIR = f\"models/mixed_model/\"\n",
    "MixedTransformer.load_model(MODEL_DIR + \"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764148487.583521 3709985 service.cc:152] XLA service 0x7f0bb401ce70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764148487.583546 3709985 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2025-11-26 10:14:47.639875: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "2025-11-26 10:14:47.668570: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1764148487.958660 3709985 cuda_dnn.cc:529] Loaded cuDNN version 91500\n",
      "I0000 00:00:1764148488.909887 3709985 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-11-26 10:14:53.613800: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "2025-11-26 10:14:58.863601: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "2025-11-26 10:15:04.599517: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"FeatureConcatTransformerModel\" is incompatible with the layer: expected shape=(None, 6, 5), found shape=(128, 6, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReconstructionEvaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#AssignmentModels.DeltaRAssigner(data_config),\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#AssignmentModels.ChiSquareAssigner(data_config, top_mass=173.5e3),\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mToponiumTransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMixedTransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mGroundTruthReconstructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPerfect Assignment + $\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnu^2$-Flows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_nu_flows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mva-trainer/notebooks/../core/evaluation/reconstruction_evaluator.py:179\u001b[0m, in \u001b[0;36mReconstructionEvaluator.__init__\u001b[0;34m(self, reconstructors, X_test, y_test)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m reconstructors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Initialize managers\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_manager \u001b[38;5;241m=\u001b[39m \u001b[43mPredictionManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreconstructors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplementarity_analyzer \u001b[38;5;241m=\u001b[39m ComplementarityAnalyzer(\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_manager, y_test\n\u001b[1;32m    182\u001b[0m )\n",
      "File \u001b[0;32m~/mva-trainer/notebooks/../core/evaluation/reconstruction_evaluator.py:50\u001b[0m, in \u001b[0;36mPredictionManager.__init__\u001b[0;34m(self, reconstructors, X_test)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test \u001b[38;5;241m=\u001b[39m X_test\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_all_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mva-trainer/notebooks/../core/evaluation/reconstruction_evaluator.py:57\u001b[0m, in \u001b[0;36mPredictionManager._compute_all_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reconstructor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreconstructors:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(reconstructor, MLReconstructorBase):\n\u001b[1;32m     56\u001b[0m         assignment_pred, neutrino_regression \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 57\u001b[0m             \u001b[43mreconstructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete_forward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     60\u001b[0m             {\n\u001b[1;32m     61\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massignment\u001b[39m\u001b[38;5;124m\"\u001b[39m: assignment_pred,\n\u001b[1;32m     62\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m: neutrino_regression,\n\u001b[1;32m     63\u001b[0m             }\n\u001b[1;32m     64\u001b[0m         )\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/mva-trainer/notebooks/../core/reconstruction/reconstruction_base.py:308\u001b[0m, in \u001b[0;36mMLReconstructorBase.complete_forward_pass\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m assignment_predictions, neutrino_reconstruction\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     assignment_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclusive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     neutrino_reconstruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreconstruct_neutrinos(data)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m assignment_predictions, neutrino_reconstruction\n",
      "File \u001b[0;32m~/mva-trainer/notebooks/../core/reconstruction/reconstruction_base.py:221\u001b[0m, in \u001b[0;36mMLReconstructorBase.predict_indices\u001b[0;34m(self, data, exclusive)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel not built. Please build the model using build_model() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmet_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlepton\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massignment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict_dict(\n\u001b[1;32m    226\u001b[0m         [data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjet\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlepton\u001b[39m\u001b[38;5;124m\"\u001b[39m]], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m\n\u001b[1;32m    227\u001b[0m     )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massignment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/mva-trainer/notebooks/../core/base_classes/MachineLearningBase.py:18\u001b[0m, in \u001b[0;36mKerasModelWrapper.predict_dict\u001b[0;34m(self, x, batch_size, verbose, steps, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 18\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(predictions, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(predictions, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m/data/dust/group/atlas/ttreco/venv/lib64/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/data/dust/group/atlas/ttreco/venv/lib64/python3.9/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"FeatureConcatTransformerModel\" is incompatible with the layer: expected shape=(None, 6, 5), found shape=(128, 6, 9)"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluation.ReconstructionEvaluator(\n",
    "    [\n",
    "        #AssignmentModels.DeltaRAssigner(data_config),\n",
    "        #AssignmentModels.ChiSquareAssigner(data_config, top_mass=173.5e3),\n",
    "        ToponiumTransformer,\n",
    "        Transformer,\n",
    "        MixedTransformer,\n",
    "        GroundTruthReconstructor(data_config, name=r\"Perfect Assignment + $\\nu^2$-Flows\", use_nu_flows=True),\n",
    "    ],\n",
    "    X_val,\n",
    "    y_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_all_accuracies()\n",
    "fig.savefig(PLOTS_DIR + \"all_accuracies.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ce232",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_all_selection_accuracies()\n",
    "fig.savefig(PLOTS_DIR + \"all_selection_accuracies.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_selection_accuracy(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    xlims=(340e3, 800e3),\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "\n",
    "fig.savefig(PLOTS_DIR + \"binned_selecton_accuracy_ttbar_mass_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17892f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_ttbar_mass_distributions(bins = 20, figsize=(16,16))\n",
    "fig.savefig(f\"{PLOTS_DIR}/ttbar_mass_distributions.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e07270",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_top_mass_distributions(bins = 20, figsize=(16,16))\n",
    "fig.savefig(f\"{PLOTS_DIR}/top_mass_distributions.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_ttbar_mass_deviation_distribution(bins = 20, xlims = (-0.5, 3))\n",
    "ax.set_yscale(\"log\")\n",
    "fig.savefig(f\"{PLOTS_DIR}/ttbar_mass_deviation_distribution.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = evaluator.plot_c_hel_distributions(bins = 20)\n",
    "for ax in axes:\n",
    "    ax.set_yscale(\"log\")\n",
    "fig.savefig(f\"{PLOTS_DIR}/c_hel_distributions.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5651bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = evaluator.plot_c_han_distributions(bins = 20)\n",
    "for ax in axes:\n",
    "    ax.set_yscale(\"log\")\n",
    "fig.savefig(f\"{PLOTS_DIR}/c_han_distributions.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2f15dc",
   "metadata": {},
   "source": [
    "## Resolution Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10be06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_c_hel_resolution(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    n_bootstrap=10,\n",
    "    xlims=(340e3, 800e3),\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"c_hel_resolution_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_c_han_resolution(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    n_bootstrap=10,\n",
    "    xlims=(340e3, 800e3),\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"c_han_resolution_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_ttbar_mass_resolution(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    n_bootstrap=10,\n",
    "    xlims=(340e3, 800e3),\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"ttbar_mass_resolution_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b984da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_all_accuracies(\n",
    "    n_bootstrap=10\n",
    ")\n",
    "fig.savefig(PLOTS_DIR + \"all_accuracies.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec07a7ac",
   "metadata": {},
   "source": [
    "## Accuracy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b56b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_accuracy(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"N_jets\",\n",
    "    fancy_feature_label=r\"$\\# \\text{jets}$\",\n",
    "    xlims=(2, data_configs[\"LoadConfig\"][\"max_jets\"] + 1),\n",
    "    bins=data_configs[\"LoadConfig\"][\"max_jets\"] - 1,\n",
    "    n_bootstrap=10,\n",
    ")\n",
    "ax.set_xticks([i + 0.5 for i in range(2, data_configs[\"LoadConfig\"][\"max_jets\"] + 1)])\n",
    "ax.set_xticklabels([i for i in range(2, data_configs[\"LoadConfig\"][\"max_jets\"] + 1)])\n",
    "fig.savefig(PLOTS_DIR + \"binned_accuracy_N_jets.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_accuracy(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    xlims=(340e3, 800e3),\n",
    "    bins=10,\n",
    "    n_bootstrap=10,\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"binned_accuracy_ttbar_mass.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_accuracy(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_pt\",\n",
    "    fancy_feature_label=r\"$p_T(t\\overline{t})$ [GeV]\",\n",
    "    xlims=(0, 400e3),\n",
    "    bins=10,\n",
    "    n_bootstrap=10,\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(0, 400e3)\n",
    "\n",
    "fig.savefig(PLOTS_DIR + \"binned_accuracy_ttbar_pT.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed78d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_top_mass_resolution(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    xlims=(340e3, 800e3),\n",
    "    n_bootstrap=10,\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"top_mass_resolution_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31265373",
   "metadata": {},
   "source": [
    "## Mass Resolution and Deviation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21630f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_top_mass_deviation(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    xlims=(340e3, 800e3),\n",
    "    n_bootstrap=10,\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"top_mass_deviation_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_ttbar_mass_deviation(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    n_bootstrap=10,\n",
    "    xlims=(340e3, 800e3),\n",
    ")\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels([f\"{int(tick/1e3)}\" for tick in ticks])\n",
    "ax.set_xlim(340e3, 800e3)\n",
    "fig.savefig(PLOTS_DIR + \"ttbar_mass_deviation_comparison.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71083c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_binned_selection_accuracy(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_ttbar_mass\",\n",
    "    fancy_feature_label=r\"$m(t\\overline{t})$ [GeV]\",\n",
    "    n_bootstrap=10,\n",
    "    xlims=(340e3, 800e3),\n",
    ")\n",
    "fig.savefig(PLOTS_DIR + \"binned_selection_accuracy_ttbar_mass.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ca903",
   "metadata": {},
   "source": [
    "## Confusion Matrices and Complementarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbca8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_binned_accuracy(\n",
    "    feature_data_type=\"non_training\",\n",
    "    feature_name=\"truth_initial_parton_num_gluons\",\n",
    "    fancy_feature_label=r\"Initial State\",\n",
    "    xlims=(0, 3),\n",
    "    bins=3,\n",
    "    n_bootstrap=10,\n",
    ")\n",
    "ax.set_xticks([0.5, 1.5, 2.5])\n",
    "ax.set_xticklabels([r\"$qq\\to tt$\", r\"$qg\\to tt$\", r\"$gg\\to tt$\"])\n",
    "fig.savefig(PLOTS_DIR + \"binned_accuracy_initial_state.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = evaluator.plot_confusion_matrices()\n",
    "fig.savefig(PLOTS_DIR + \"confusion_matrices.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

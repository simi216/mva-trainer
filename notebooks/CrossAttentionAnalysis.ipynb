{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f7c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:42:05.829857: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-22 14:42:05.830573: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-22 14:42:05.833728: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-22 14:42:05.841722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761136925.854721 3792729 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761136925.858544 3792729 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761136925.869968 3792729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761136925.869983 3792729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761136925.869985 3792729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761136925.869987 3792729 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-22 14:42:05.873938: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Ensure the parent directory is in the path\n",
    "\n",
    "import core.assingment as Models\n",
    "from core.DataLoader import DataPreprocessor, DataConfig\n",
    "import core\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MAX_JETS = 6\n",
    "PLOTS_DIR = f\"plots/\"\n",
    "import os\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "\n",
    "config = DataConfig(\n",
    "    jet_features=[\n",
    "        \"ordered_jet_pt\",\n",
    "        \"ordered_jet_eta\",\n",
    "        \"ordered_jet_phi\",\n",
    "        \"ordered_jet_e\",\n",
    "        \"ordered_jet_b_tag\",\n",
    "    ],\n",
    "    lepton_features=[\"lep_pt\", \"lep_eta\", \"lep_phi\", \"lep_e\"],\n",
    "    jet_truth_label=\"ordered_event_jet_truth_idx\",\n",
    "    lepton_truth_label=\"event_lepton_truth_idx\",\n",
    "    met_features=[\"met_met_NOSYS\", \"met_phi_NOSYS\"],\n",
    "    max_leptons=2,\n",
    "    max_jets=MAX_JETS,\n",
    "    non_training_features=[\"truth_ttbar_mass\", \"truth_ttbar_pt\", \"N_jets\"],\n",
    "    event_weight=\"weight_mc_NOSYS\",\n",
    ")\n",
    "\n",
    "DataProcessor = DataPreprocessor(config)\n",
    "DataProcessor.load_data(\n",
    "    \"/data/dust/group/atlas/ttreco/full_training.root\", \"reco\", max_events=1000000\n",
    ")\n",
    "# DataProcessor.normalise_data()\n",
    "X_train, y_train, X_val, y_val = DataProcessor.split_data(\n",
    "    test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d8dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 14:42:45.477452: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CrossAttentionModel\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CrossAttentionModel\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ met_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ met_input_transform │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ met_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputMetPhiLayer</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ met_input_normaliz… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ met_input_transf… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_input_transform │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputPtEtaPhiELay…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ met_input_normal… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_input_normaliz… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ jet_input_transf… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_input_normal… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,546</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GenerateMask</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ jet_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_input_transform │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lep_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputPtEtaPhiELay…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_input_normaliz… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ lep_input_transf… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lep_input_normal… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,417</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leps_cross_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,600</span> │ lep_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ self_attention_b… │\n",
       "│                     │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jets_cross_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,600</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ leps_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leps_cross_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,600</span> │ leps_cross_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ jets_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jets_cross_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,600</span> │ jets_cross_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ leps_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_lepton_assignm… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ jets_cross_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">JetLeptonAssignme…</span> │                   │            │ leps_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ met_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ met_input_transform │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ met_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mInputMetPhiLayer\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ met_input_normaliz… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m5\u001b[0m │ met_input_transf… │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_input_transform │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mInputPtEtaPhiELay…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ met_input_normal… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_input_normaliz… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │         \u001b[38;5;34m11\u001b[0m │ jet_input_transf… │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m7\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_input_normal… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_embedding (\u001b[38;5;33mMLP\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m2,546\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGenerateMask\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ jet_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_input_transform │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ lep_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mInputPtEtaPhiELay…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_input_normaliz… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │          \u001b[38;5;34m9\u001b[0m │ lep_input_transf… │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ lep_input_normal… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_embedding (\u001b[38;5;33mMLP\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m2,417\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leps_cross_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,600\u001b[0m │ lep_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ self_attention_b… │\n",
       "│                     │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jets_cross_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,600\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ leps_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leps_cross_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,600\u001b[0m │ leps_cross_atten… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ jets_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jets_cross_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,600\u001b[0m │ jets_cross_atten… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ leps_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_lepton_assignm… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ jets_cross_atten… │\n",
       "│ (\u001b[38;5;33mJetLeptonAssignme…\u001b[0m │                   │            │ leps_cross_atten… │\n",
       "│                     │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281,596</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m281,596\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">281,571</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m281,571\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (112.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m25\u001b[0m (112.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.CrossAttentionModel(config, name=\"Transformer\")\n",
    "\n",
    "TransformerMatcher.build_model(\n",
    "    hidden_dim=64,\n",
    "    num_decoder_layers=2,\n",
    "    num_encoder_layers=4,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "TransformerMatcher.adapt_normalization_layers(X_train)\n",
    "\n",
    "TransformerMatcher.compile_model(\n",
    "    loss = core.utils.AssignmentLoss(lambda_excl=0), optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4), metrics=[core.utils.AssignmentAccuracy()]\n",
    ")\n",
    "TransformerMatcher.model.summary()\n",
    "#TransformerMatcher.load_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adc6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 344ms/step - assignment_accuracy: 0.1972 - loss: 0.5596 - val_assignment_accuracy: 0.4402 - val_loss: 0.4000\n",
      "Epoch 2/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 378ms/step - assignment_accuracy: 0.4167 - loss: 0.4340 - val_assignment_accuracy: 0.6119 - val_loss: 0.3378\n",
      "Epoch 3/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 384ms/step - assignment_accuracy: 0.5396 - loss: 0.3879 - val_assignment_accuracy: 0.6528 - val_loss: 0.3132\n",
      "Epoch 4/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 388ms/step - assignment_accuracy: 0.5879 - loss: 0.3613 - val_assignment_accuracy: 0.6823 - val_loss: 0.2928\n",
      "Epoch 5/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 368ms/step - assignment_accuracy: 0.6163 - loss: 0.3425 - val_assignment_accuracy: 0.6985 - val_loss: 0.2825\n",
      "Epoch 6/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 353ms/step - assignment_accuracy: 0.6363 - loss: 0.3294 - val_assignment_accuracy: 0.7068 - val_loss: 0.2742\n",
      "Epoch 7/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 389ms/step - assignment_accuracy: 0.6492 - loss: 0.3210 - val_assignment_accuracy: 0.7127 - val_loss: 0.2690\n",
      "Epoch 8/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 384ms/step - assignment_accuracy: 0.6591 - loss: 0.3120 - val_assignment_accuracy: 0.7143 - val_loss: 0.2644\n",
      "Epoch 9/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 368ms/step - assignment_accuracy: 0.6672 - loss: 0.3064 - val_assignment_accuracy: 0.7280 - val_loss: 0.2617\n",
      "Epoch 10/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 389ms/step - assignment_accuracy: 0.6721 - loss: 0.3024 - val_assignment_accuracy: 0.7277 - val_loss: 0.2595\n",
      "Epoch 11/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 407ms/step - assignment_accuracy: 0.6782 - loss: 0.2967 - val_assignment_accuracy: 0.7235 - val_loss: 0.2598\n",
      "Epoch 12/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 392ms/step - assignment_accuracy: 0.6825 - loss: 0.2935 - val_assignment_accuracy: 0.7288 - val_loss: 0.2586\n",
      "Epoch 13/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 393ms/step - assignment_accuracy: 0.6867 - loss: 0.2890 - val_assignment_accuracy: 0.7333 - val_loss: 0.2537\n",
      "Epoch 14/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 392ms/step - assignment_accuracy: 0.6919 - loss: 0.2850 - val_assignment_accuracy: 0.7432 - val_loss: 0.2471\n",
      "Epoch 15/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 442ms/step - assignment_accuracy: 0.6945 - loss: 0.2833 - val_assignment_accuracy: 0.7360 - val_loss: 0.2539\n",
      "Epoch 16/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 402ms/step - assignment_accuracy: 0.6997 - loss: 0.2801 - val_assignment_accuracy: 0.7390 - val_loss: 0.2492\n",
      "Epoch 17/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 379ms/step - assignment_accuracy: 0.7011 - loss: 0.2794 - val_assignment_accuracy: 0.7417 - val_loss: 0.2506\n",
      "Epoch 18/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 407ms/step - assignment_accuracy: 0.7045 - loss: 0.2764 - val_assignment_accuracy: 0.7458 - val_loss: 0.2481\n",
      "Epoch 19/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 384ms/step - assignment_accuracy: 0.7080 - loss: 0.2744 - val_assignment_accuracy: 0.7434 - val_loss: 0.2491\n",
      "Epoch 20/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 373ms/step - assignment_accuracy: 0.7103 - loss: 0.2719 - val_assignment_accuracy: 0.7414 - val_loss: 0.2477\n",
      "Epoch 21/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 382ms/step - assignment_accuracy: 0.7119 - loss: 0.2725 - val_assignment_accuracy: 0.7502 - val_loss: 0.2454\n",
      "Epoch 22/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 385ms/step - assignment_accuracy: 0.7150 - loss: 0.2688 - val_assignment_accuracy: 0.7489 - val_loss: 0.2461\n",
      "Epoch 23/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 351ms/step - assignment_accuracy: 0.7178 - loss: 0.2672 - val_assignment_accuracy: 0.7425 - val_loss: 0.2475\n",
      "Epoch 24/50\n",
      "\u001b[1m699/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 338ms/step - assignment_accuracy: 0.7188 - loss: 0.2664 - val_assignment_accuracy: 0.7475 - val_loss: 0.2460\n",
      "Epoch 25/50\n",
      "\u001b[1m536/699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m52s\u001b[0m 322ms/step - assignment_accuracy: 0.7203 - loss: 0.2638"
     ]
    }
   ],
   "source": [
    "TransformerMatcher.train_model(epochs=50,\n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "                                batch_size=1028,\n",
    "                                callbacks = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True, mode =\"min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.save_model(\"CrossAttention_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = TransformerMatcher.predict_indices(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ConfusionMatrixDisplay.from_predictions(y_val[:,:,1].argmax(axis=-1),pred_val[:,:,1].argmax(axis=-1), normalize=\"true\", ax=ax)\n",
    "plt.savefig(PLOTS_DIR+\"/Cross_Attention_confusion_matrix_lepton.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d524bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(core)\n",
    "ml_eval = core.assingment.MLEvaluatorBase(TransformerMatcher, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_eval.plot_feature_importance(num_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499be253",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.export_to_onnx(\"CrossAttention_Assignment.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "onnx_model = onnx.load(\"CrossAttention_Assignment.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "ort_session = ort.InferenceSession(\"CrossAttention_Assignment.onnx\")\n",
    "flatted_inputs = np.concatenate([X_val['jet'].reshape(X_val['jet'].shape[0], -1), X_val['lepton'].reshape(X_val['lepton'].shape[0], -1), X_val['global'].reshape(X_val[\"global\"].shape[0],-1)], axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e31ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ort_session.run(None, {\"flat_input\": flatted_inputs})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_val[:,:,0].argmax(axis=-1),outputs[:,:,0].argmax(axis=-1), normalize=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff42a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"Transformer_Assignment.onnx\")\n",
    "print([inp.name for inp in model.graph.input])\n",
    "print([out.name for out in model.graph.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.assingment.BaselineMethods as BaselineMethods\n",
    "import core.assingment.Evaluation as Evaluation\n",
    "reload(Evaluation)\n",
    "reload(BaselineMethods)\n",
    "delta_r_assigner = BaselineMethods.DeltaRAssigner(config, name=r\"$\\Delta R$-Assignment\")\n",
    "invariant_mass_assigner = BaselineMethods.LeptonJetMassAssigner(config, name = r\"$m(\\ell, j)$-Assignment\")\n",
    "\n",
    "evaluator = Evaluation.JetAssignmentEvaluator([delta_r_assigner,invariant_mass_assigner,TransformerMatcher], X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_binned_accuracy(feature_data_type='non_training', feature_name='truth_ttbar_mass', xlims = (340e3,800e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_confusion_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044a784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

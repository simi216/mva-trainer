{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 10:54:24.578890: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764582864.601923 3029079 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764582864.609793 3029079 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764582864.628538 3029079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764582864.628561 3029079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764582864.628564 3029079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764582864.628566 3029079 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-12-01 10:54:24.633864: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from core.DataLoader import (\n",
    "    DataPreprocessor,\n",
    "    DataConfig,\n",
    "    LoadConfig,\n",
    "    get_load_config_from_yaml,\n",
    "    combine_train_datasets\n",
    ")\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import core.assignment_models as Models\n",
    "import core\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "PLOTS_DIR = f\"plots/mixed_model/\"\n",
    "MODEL_DIR = f\"models/mixed_model\"\n",
    "#MODEL_DIR = f\"../models/FeatureConcatTransformer_HLF_d256_l10_h8\"\n",
    "CONFIG_PATH = \"../config/workspace_config.yaml\"\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "load_config = get_load_config_from_yaml(CONFIG_PATH)\n",
    "\n",
    "DataProcessorNominal = DataPreprocessor(load_config)\n",
    "DataProcessorToponium = DataPreprocessor(load_config)\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as file:\n",
    "    data_configs = yaml.safe_load(file)\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "data_config = DataProcessorNominal.load_from_npz(data_configs[\"data_path\"][\"nominal\"], max_events=2000000)\n",
    "DataProcessorToponium.load_from_npz(data_configs[\"data_path\"][\"toponium\"])\n",
    "\n",
    "X_nominal, y_nominal = DataProcessorNominal.get_data()\n",
    "X_toponium, y_toponium = DataProcessorToponium.get_data()\n",
    "X_train, y_train = combine_train_datasets(\n",
    "    [X_nominal, X_toponium],\n",
    "    [y_nominal, y_toponium],\n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.CrossAttentionModel(data_config, name=r\"Transformer + $\\nu^2$-Flows\")\n",
    "\n",
    "#TransformerMatcher.load_model(f\"{MODEL_DIR}/model.keras\")\n",
    "TransformerMatcher.build_model(\n",
    "    hidden_dim=128,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "TransformerMatcher.adapt_normalization_layers(X_train)\n",
    "\n",
    "TransformerMatcher.compile_model(\n",
    "    loss={\n",
    "        \"assignment\": core.utils.AssignmentLoss(lambda_excl=0.0),\n",
    "    },\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4),\n",
    "    metrics={\n",
    "        \"assignment\": [core.utils.AssignmentAccuracy()],\n",
    "    },\n",
    ")\n",
    "TransformerMatcher.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.train_model(\n",
    "    epochs=100,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "    batch_size=1024,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_assignment_loss\",\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode=\"min\",\n",
    "            min_lr=1e-6,\n",
    "        ),\n",
    "    ],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.model.save(f\"{MODEL_DIR}/model.keras\")\n",
    "#TransformerMatcher.save_model(f\"{MODEL_DIR}/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c90b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

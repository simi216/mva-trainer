{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 15:36:45.782737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764340605.805464 3003856 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764340605.812787 3003856 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764340605.831861 3003856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764340605.831888 3003856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764340605.831891 3003856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764340605.831893 3003856 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-28 15:36:45.837511: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from core.DataLoader import (\n",
    "    DataPreprocessor,\n",
    "    DataConfig,\n",
    "    LoadConfig,\n",
    "    get_load_config_from_yaml,\n",
    ")\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import core.assignment_models as Models\n",
    "import core\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "PLOTS_DIR = f\"plots/toponium_transformer_HLF/\"\n",
    "MODEL_DIR = f\"models/toponium_transformer_HLF/\"\n",
    "CONFIG_PATH = \"../config/workspace_config_HLF.yaml\"\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "\n",
    "load_config = get_load_config_from_yaml(CONFIG_PATH)\n",
    "\n",
    "DataProcessor = DataPreprocessor(load_config)\n",
    "\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "data_config = DataProcessor.load_from_npz(\n",
    "    load_config[\"toponium\"], max_events=1_000_000\n",
    ")\n",
    "X_train, y_train, X_val, y_val = DataProcessor.split_data(test_size=0.1)\n",
    "del DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureConcatTransformer is designed for classification tasks; regression targets will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764340629.516705 3003856 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15511 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:65:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Regression targets are specified in the config, but regression_output is None.\n",
      "Building model without regression output.\n"
     ]
    }
   ],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.FeatureConcatTransformer(data_config, name=\"ToponiumTransformer\")\n",
    "\n",
    "TransformerMatcher.build_model(\n",
    "    hidden_dim=64,\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "TransformerMatcher.adapt_normalization_layers(X_train)\n",
    "#TransformerMatcher.load_model(MODEL_DIR + \"model.keras\")\n",
    "\n",
    "TransformerMatcher.compile_model(\n",
    "    loss={\n",
    "        \"assignment\": core.utils.AssignmentLoss(lambda_excl=0.0),\n",
    "    },\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4),\n",
    "    metrics={\n",
    "        \"assignment\": [core.utils.AssignmentAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764340648.862250 3004435 service.cc:152] XLA service 0x7f37a00124e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764340648.862291 3004435 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2025-11-28 15:37:29.454350: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-28 15:37:30.138735: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1764340651.919296 3004435 cuda_dnn.cc:529] Loaded cuDNN version 91500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  8/702\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.1432 - loss: 0.1972 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764340665.726238 3004435 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m701/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2677 - loss: 0.1575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 15:37:57.614641: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2678 - loss: 0.1575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 15:38:14.703684: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "2025-11-28 15:38:16.712271: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 46ms/step - accuracy: 0.2680 - loss: 0.1575 - val_accuracy: 0.5767 - val_loss: 0.1081\n",
      "Epoch 2/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.5285 - loss: 0.1173 - val_accuracy: 0.6527 - val_loss: 0.0953\n",
      "Epoch 3/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.6112 - loss: 0.1048 - val_accuracy: 0.6876 - val_loss: 0.0904\n",
      "Epoch 4/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6434 - loss: 0.0991 - val_accuracy: 0.7040 - val_loss: 0.0877\n",
      "Epoch 5/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6582 - loss: 0.0957 - val_accuracy: 0.7101 - val_loss: 0.0851\n",
      "Epoch 6/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6671 - loss: 0.0935 - val_accuracy: 0.7127 - val_loss: 0.0837\n",
      "Epoch 7/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6765 - loss: 0.0915 - val_accuracy: 0.7233 - val_loss: 0.0821\n",
      "Epoch 8/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6826 - loss: 0.0899 - val_accuracy: 0.7266 - val_loss: 0.0807\n",
      "Epoch 9/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6895 - loss: 0.0882 - val_accuracy: 0.7312 - val_loss: 0.0797\n",
      "Epoch 10/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6940 - loss: 0.0870 - val_accuracy: 0.7337 - val_loss: 0.0787\n",
      "Epoch 11/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6975 - loss: 0.0861 - val_accuracy: 0.7342 - val_loss: 0.0780\n",
      "Epoch 12/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7006 - loss: 0.0854 - val_accuracy: 0.7394 - val_loss: 0.0772\n",
      "Epoch 13/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7048 - loss: 0.0843 - val_accuracy: 0.7417 - val_loss: 0.0768\n",
      "Epoch 14/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7066 - loss: 0.0838 - val_accuracy: 0.7447 - val_loss: 0.0760\n",
      "Epoch 15/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7114 - loss: 0.0827 - val_accuracy: 0.7451 - val_loss: 0.0753\n",
      "Epoch 16/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7123 - loss: 0.0822 - val_accuracy: 0.7485 - val_loss: 0.0749\n",
      "Epoch 17/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7172 - loss: 0.0815 - val_accuracy: 0.7484 - val_loss: 0.0750\n",
      "Epoch 18/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7180 - loss: 0.0812 - val_accuracy: 0.7523 - val_loss: 0.0743\n",
      "Epoch 19/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7216 - loss: 0.0804 - val_accuracy: 0.7505 - val_loss: 0.0741\n",
      "Epoch 20/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7223 - loss: 0.0802 - val_accuracy: 0.7545 - val_loss: 0.0740\n",
      "Epoch 21/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7248 - loss: 0.0797 - val_accuracy: 0.7569 - val_loss: 0.0734\n",
      "Epoch 22/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7261 - loss: 0.0795 - val_accuracy: 0.7580 - val_loss: 0.0731\n",
      "Epoch 23/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7272 - loss: 0.0793 - val_accuracy: 0.7593 - val_loss: 0.0727\n",
      "Epoch 24/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7291 - loss: 0.0788 - val_accuracy: 0.7579 - val_loss: 0.0727\n",
      "Epoch 25/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7307 - loss: 0.0787 - val_accuracy: 0.7604 - val_loss: 0.0727\n",
      "Epoch 26/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7324 - loss: 0.0783 - val_accuracy: 0.7609 - val_loss: 0.0723\n",
      "Epoch 27/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7346 - loss: 0.0777 - val_accuracy: 0.7630 - val_loss: 0.0719\n",
      "Epoch 28/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7339 - loss: 0.0779 - val_accuracy: 0.7631 - val_loss: 0.0719\n",
      "Epoch 29/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7338 - loss: 0.0777 - val_accuracy: 0.7622 - val_loss: 0.0721\n",
      "Epoch 30/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7365 - loss: 0.0773 - val_accuracy: 0.7636 - val_loss: 0.0722\n",
      "Epoch 31/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7373 - loss: 0.0771 - val_accuracy: 0.7618 - val_loss: 0.0721\n",
      "Epoch 32/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7382 - loss: 0.0769 - val_accuracy: 0.7637 - val_loss: 0.0719\n",
      "Epoch 33/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7396 - loss: 0.0767 - val_accuracy: 0.7648 - val_loss: 0.0715\n",
      "Epoch 34/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7399 - loss: 0.0765 - val_accuracy: 0.7654 - val_loss: 0.0716\n",
      "Epoch 35/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7402 - loss: 0.0766 - val_accuracy: 0.7652 - val_loss: 0.0719\n",
      "Epoch 36/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7413 - loss: 0.0764 - val_accuracy: 0.7654 - val_loss: 0.0716\n",
      "Epoch 37/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7426 - loss: 0.0759 - val_accuracy: 0.7662 - val_loss: 0.0712\n",
      "Epoch 38/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7428 - loss: 0.0760 - val_accuracy: 0.7696 - val_loss: 0.0709\n",
      "Epoch 39/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7433 - loss: 0.0759 - val_accuracy: 0.7656 - val_loss: 0.0714\n",
      "Epoch 40/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7453 - loss: 0.0757 - val_accuracy: 0.7697 - val_loss: 0.0707\n",
      "Epoch 41/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7448 - loss: 0.0757 - val_accuracy: 0.7681 - val_loss: 0.0712\n",
      "Epoch 42/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7455 - loss: 0.0755 - val_accuracy: 0.7700 - val_loss: 0.0707\n",
      "Epoch 43/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7449 - loss: 0.0755 - val_accuracy: 0.7705 - val_loss: 0.0707\n",
      "Epoch 44/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7463 - loss: 0.0754 - val_accuracy: 0.7706 - val_loss: 0.0707\n",
      "Epoch 45/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7475 - loss: 0.0752 - val_accuracy: 0.7663 - val_loss: 0.0715\n",
      "Epoch 46/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7473 - loss: 0.0752 - val_accuracy: 0.7696 - val_loss: 0.0708\n",
      "Epoch 47/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7477 - loss: 0.0750 - val_accuracy: 0.7703 - val_loss: 0.0706\n",
      "Epoch 48/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7488 - loss: 0.0749 - val_accuracy: 0.7739 - val_loss: 0.0697\n",
      "Epoch 49/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7489 - loss: 0.0748 - val_accuracy: 0.7732 - val_loss: 0.0701\n",
      "Epoch 50/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7501 - loss: 0.0747 - val_accuracy: 0.7743 - val_loss: 0.0700\n",
      "Epoch 51/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7504 - loss: 0.0745 - val_accuracy: 0.7718 - val_loss: 0.0700\n",
      "Epoch 52/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7506 - loss: 0.0745 - val_accuracy: 0.7721 - val_loss: 0.0703\n",
      "Epoch 53/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7498 - loss: 0.0745 - val_accuracy: 0.7738 - val_loss: 0.0696\n",
      "Epoch 54/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7493 - loss: 0.0747 - val_accuracy: 0.7751 - val_loss: 0.0699\n",
      "Epoch 55/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7517 - loss: 0.0741 - val_accuracy: 0.7740 - val_loss: 0.0703\n",
      "Epoch 56/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7523 - loss: 0.0742 - val_accuracy: 0.7735 - val_loss: 0.0702\n",
      "Epoch 57/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7521 - loss: 0.0743 - val_accuracy: 0.7755 - val_loss: 0.0696\n",
      "Epoch 58/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7531 - loss: 0.0741 - val_accuracy: 0.7759 - val_loss: 0.0695\n",
      "Epoch 59/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7533 - loss: 0.0740 - val_accuracy: 0.7759 - val_loss: 0.0694\n",
      "Epoch 60/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7535 - loss: 0.0738 - val_accuracy: 0.7760 - val_loss: 0.0692\n",
      "Epoch 61/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7531 - loss: 0.0739 - val_accuracy: 0.7755 - val_loss: 0.0698\n",
      "Epoch 62/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7542 - loss: 0.0738 - val_accuracy: 0.7744 - val_loss: 0.0700\n",
      "Epoch 63/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7534 - loss: 0.0739 - val_accuracy: 0.7763 - val_loss: 0.0700\n",
      "Epoch 64/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7541 - loss: 0.0738 - val_accuracy: 0.7765 - val_loss: 0.0694\n",
      "Epoch 65/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7544 - loss: 0.0737 - val_accuracy: 0.7771 - val_loss: 0.0691\n",
      "Epoch 66/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7560 - loss: 0.0733 - val_accuracy: 0.7733 - val_loss: 0.0702\n",
      "Epoch 67/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7562 - loss: 0.0734 - val_accuracy: 0.7788 - val_loss: 0.0690\n",
      "Epoch 68/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7554 - loss: 0.0735 - val_accuracy: 0.7789 - val_loss: 0.0692\n",
      "Epoch 69/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7571 - loss: 0.0732 - val_accuracy: 0.7754 - val_loss: 0.0697\n",
      "Epoch 70/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7560 - loss: 0.0734 - val_accuracy: 0.7757 - val_loss: 0.0697\n",
      "Epoch 71/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7575 - loss: 0.0732 - val_accuracy: 0.7776 - val_loss: 0.0691\n",
      "Epoch 72/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7561 - loss: 0.0733 - val_accuracy: 0.7765 - val_loss: 0.0694\n",
      "Epoch 73/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7564 - loss: 0.0731 - val_accuracy: 0.7759 - val_loss: 0.0697\n",
      "Epoch 74/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7579 - loss: 0.0731 - val_accuracy: 0.7773 - val_loss: 0.0694\n",
      "Epoch 75/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7570 - loss: 0.0729 - val_accuracy: 0.7792 - val_loss: 0.0688\n",
      "Epoch 76/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7577 - loss: 0.0729 - val_accuracy: 0.7779 - val_loss: 0.0691\n",
      "Epoch 77/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7582 - loss: 0.0728 - val_accuracy: 0.7753 - val_loss: 0.0696\n",
      "Epoch 78/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7583 - loss: 0.0727 - val_accuracy: 0.7777 - val_loss: 0.0696\n",
      "Epoch 79/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7579 - loss: 0.0728 - val_accuracy: 0.7796 - val_loss: 0.0692\n",
      "Epoch 80/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7591 - loss: 0.0727 - val_accuracy: 0.7748 - val_loss: 0.0701\n",
      "Epoch 81/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7604 - loss: 0.0724 - val_accuracy: 0.7796 - val_loss: 0.0688\n",
      "Epoch 82/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7595 - loss: 0.0725 - val_accuracy: 0.7794 - val_loss: 0.0689\n",
      "Epoch 83/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7601 - loss: 0.0725 - val_accuracy: 0.7769 - val_loss: 0.0697\n",
      "Epoch 84/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7603 - loss: 0.0725 - val_accuracy: 0.7822 - val_loss: 0.0687\n",
      "Epoch 85/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7598 - loss: 0.0724 - val_accuracy: 0.7790 - val_loss: 0.0688\n",
      "Epoch 86/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7590 - loss: 0.0725 - val_accuracy: 0.7812 - val_loss: 0.0690\n",
      "Epoch 87/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7600 - loss: 0.0724 - val_accuracy: 0.7803 - val_loss: 0.0689\n",
      "Epoch 88/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7611 - loss: 0.0724 - val_accuracy: 0.7822 - val_loss: 0.0686\n",
      "Epoch 89/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7613 - loss: 0.0723 - val_accuracy: 0.7817 - val_loss: 0.0686\n",
      "Epoch 90/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7619 - loss: 0.0719 - val_accuracy: 0.7783 - val_loss: 0.0692\n",
      "Epoch 91/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7620 - loss: 0.0720 - val_accuracy: 0.7792 - val_loss: 0.0689\n",
      "Epoch 92/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7608 - loss: 0.0721 - val_accuracy: 0.7809 - val_loss: 0.0683\n",
      "Epoch 93/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7614 - loss: 0.0722 - val_accuracy: 0.7816 - val_loss: 0.0680\n",
      "Epoch 94/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7632 - loss: 0.0719 - val_accuracy: 0.7787 - val_loss: 0.0692\n",
      "Epoch 95/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7623 - loss: 0.0719 - val_accuracy: 0.7805 - val_loss: 0.0686\n",
      "Epoch 96/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7637 - loss: 0.0716 - val_accuracy: 0.7794 - val_loss: 0.0691\n",
      "Epoch 97/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7627 - loss: 0.0719 - val_accuracy: 0.7801 - val_loss: 0.0689\n",
      "Epoch 98/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7633 - loss: 0.0719 - val_accuracy: 0.7793 - val_loss: 0.0683\n",
      "Epoch 99/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7636 - loss: 0.0717 - val_accuracy: 0.7828 - val_loss: 0.0682\n",
      "Epoch 100/100\n",
      "\u001b[1m702/702\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7634 - loss: 0.0716 - val_accuracy: 0.7803 - val_loss: 0.0685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f390ffbda90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformerMatcher.train_model(\n",
    "    epochs=100,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "    batch_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/toponium_transformer_HLF/model.keras\n"
     ]
    }
   ],
   "source": [
    "TransformerMatcher.save_model(MODEL_DIR + \"model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

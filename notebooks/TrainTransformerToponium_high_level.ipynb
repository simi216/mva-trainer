{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 10:58:42.287256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763719122.311759  382178 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763719122.319808  382178 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1763719122.339243  382178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763719122.339269  382178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763719122.339271  382178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1763719122.339274  382178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-21 10:58:42.345021: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from core.DataLoader import (\n",
    "    DataPreprocessor,\n",
    "    DataConfig,\n",
    "    LoadConfig,\n",
    "    get_load_config_from_yaml,\n",
    ")\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import core.assignment_models as Models\n",
    "import core\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "PLOTS_DIR = f\"plots/toponium_transformer_HLF/\"\n",
    "MODEL_DIR = f\"models/toponium_transformer_HLF/\"\n",
    "CONFIG_PATH = \"../config/workspace_config_HLF.yaml\"\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "\n",
    "load_config = get_load_config_from_yaml(CONFIG_PATH)\n",
    "\n",
    "DataProcessor = DataPreprocessor(load_config)\n",
    "\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as file:\n",
    "    data_configs = yaml.safe_load(file)\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "data_config = DataProcessor.load_from_npz(\n",
    "    data_configs[\"data_path\"][\"toponium\"]\n",
    ")\n",
    "X_train, y_train, X_val, y_val = DataProcessor.split_data(test_size=0.1)\n",
    "del DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureConcatTransformer is designed for classification tasks; regression targets will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763719167.654531  382178 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15511 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:65:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Regression targets are specified in the config, but regression_output is None.\n",
      "Building model without regression output.\n"
     ]
    }
   ],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.FeatureConcatTransformer(data_config, name=\"ToponiumTransformer\")\n",
    "\n",
    "TransformerMatcher.build_model(\n",
    "    hidden_dim=64,\n",
    "    num_layers=6,\n",
    "    num_heads=8,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "TransformerMatcher.adapt_normalization_layers(X_train)\n",
    "#TransformerMatcher.load_model(MODEL_DIR + \"model.keras\")\n",
    "\n",
    "TransformerMatcher.compile_model(\n",
    "    loss={\n",
    "        \"assignment\": core.utils.AssignmentLoss(lambda_excl=0.0),\n",
    "    },\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4),\n",
    "    metrics={\n",
    "        \"assignment\": [core.utils.AssignmentAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763719187.812559  383826 service.cc:152] XLA service 0x7f917000f380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1763719187.812599  383826 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2025-11-21 10:59:48.404412: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-21 10:59:49.079589: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1763719190.854103  383826 cuda_dnn.cc:529] Loaded cuDNN version 91500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   8/1073\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - accuracy: 0.0849 - loss: 0.0014 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763719205.192387  383826 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1071/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0819 - loss: 0.0010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 11:00:22.701228: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0821 - loss: 0.0010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 11:00:39.384095: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n",
      "2025-11-21 11:00:41.818879: W tensorflow/compiler/tf2xla/kernels/assert_op.cc:39] Ignoring Assert operator FeatureConcatTransformerModel_1/met_input_transform_1/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 35ms/step - accuracy: 0.0822 - loss: 0.0010 - val_accuracy: 0.5038 - val_loss: 7.6141e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.4722 - loss: 8.0958e-04 - val_accuracy: 0.5639 - val_loss: 6.7815e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.5411 - loss: 7.3461e-04 - val_accuracy: 0.6197 - val_loss: 6.3232e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.5877 - loss: 6.8866e-04 - val_accuracy: 0.6536 - val_loss: 6.0649e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6215 - loss: 6.5699e-04 - val_accuracy: 0.6770 - val_loss: 5.8770e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6456 - loss: 6.3482e-04 - val_accuracy: 0.6988 - val_loss: 5.7244e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6638 - loss: 6.1837e-04 - val_accuracy: 0.7123 - val_loss: 5.6359e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6762 - loss: 6.0457e-04 - val_accuracy: 0.7145 - val_loss: 5.5232e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6834 - loss: 5.9721e-04 - val_accuracy: 0.7225 - val_loss: 5.4803e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.6909 - loss: 5.9133e-04 - val_accuracy: 0.7264 - val_loss: 5.4244e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6963 - loss: 5.8421e-04 - val_accuracy: 0.7274 - val_loss: 5.3627e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.6992 - loss: 5.7692e-04 - val_accuracy: 0.7317 - val_loss: 5.3314e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7029 - loss: 5.7398e-04 - val_accuracy: 0.7342 - val_loss: 5.2921e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7036 - loss: 5.7092e-04 - val_accuracy: 0.7340 - val_loss: 5.3456e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.7065 - loss: 5.6578e-04 - val_accuracy: 0.7361 - val_loss: 5.2579e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.7087 - loss: 5.6394e-04 - val_accuracy: 0.7347 - val_loss: 5.2418e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7094 - loss: 5.6065e-04 - val_accuracy: 0.7389 - val_loss: 5.2301e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - accuracy: 0.7124 - loss: 5.5861e-04 - val_accuracy: 0.7399 - val_loss: 5.1994e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7136 - loss: 5.5580e-04 - val_accuracy: 0.7433 - val_loss: 5.1679e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7161 - loss: 5.5239e-04 - val_accuracy: 0.7443 - val_loss: 5.1573e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7177 - loss: 5.5032e-04 - val_accuracy: 0.7460 - val_loss: 5.1392e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7192 - loss: 5.4870e-04 - val_accuracy: 0.7450 - val_loss: 5.1196e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7208 - loss: 5.4751e-04 - val_accuracy: 0.7448 - val_loss: 5.1055e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7211 - loss: 5.4273e-04 - val_accuracy: 0.7441 - val_loss: 5.1115e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7229 - loss: 5.4217e-04 - val_accuracy: 0.7462 - val_loss: 5.1253e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7224 - loss: 5.4349e-04 - val_accuracy: 0.7507 - val_loss: 5.0587e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.7247 - loss: 5.3820e-04 - val_accuracy: 0.7494 - val_loss: 5.0444e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.7258 - loss: 5.3907e-04 - val_accuracy: 0.7507 - val_loss: 5.0593e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7268 - loss: 5.3718e-04 - val_accuracy: 0.7469 - val_loss: 5.0858e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7274 - loss: 5.3497e-04 - val_accuracy: 0.7504 - val_loss: 5.0072e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7282 - loss: 5.3489e-04 - val_accuracy: 0.7454 - val_loss: 5.0957e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7292 - loss: 5.3281e-04 - val_accuracy: 0.7492 - val_loss: 5.0009e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7300 - loss: 5.3040e-04 - val_accuracy: 0.7525 - val_loss: 5.0139e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7307 - loss: 5.2839e-04 - val_accuracy: 0.7549 - val_loss: 4.9753e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7325 - loss: 5.2671e-04 - val_accuracy: 0.7527 - val_loss: 4.9837e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7321 - loss: 5.2860e-04 - val_accuracy: 0.7545 - val_loss: 4.9644e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7329 - loss: 5.2493e-04 - val_accuracy: 0.7562 - val_loss: 4.9670e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7326 - loss: 5.2915e-04 - val_accuracy: 0.7524 - val_loss: 4.9467e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7334 - loss: 5.2555e-04 - val_accuracy: 0.7563 - val_loss: 4.9698e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7344 - loss: 5.2248e-04 - val_accuracy: 0.7549 - val_loss: 4.9349e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7356 - loss: 5.2269e-04 - val_accuracy: 0.7574 - val_loss: 4.9214e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7356 - loss: 5.2144e-04 - val_accuracy: 0.7577 - val_loss: 4.9313e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7365 - loss: 5.1779e-04 - val_accuracy: 0.7572 - val_loss: 4.9426e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7377 - loss: 5.1986e-04 - val_accuracy: 0.7582 - val_loss: 4.8858e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7372 - loss: 5.1993e-04 - val_accuracy: 0.7539 - val_loss: 4.9681e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7378 - loss: 5.1879e-04 - val_accuracy: 0.7583 - val_loss: 4.9035e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7402 - loss: 5.1374e-04 - val_accuracy: 0.7588 - val_loss: 4.8982e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7386 - loss: 5.1535e-04 - val_accuracy: 0.7554 - val_loss: 4.9415e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7385 - loss: 5.1539e-04 - val_accuracy: 0.7597 - val_loss: 4.8702e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7406 - loss: 5.1387e-04 - val_accuracy: 0.7609 - val_loss: 4.8471e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7402 - loss: 5.1197e-04 - val_accuracy: 0.7606 - val_loss: 4.8451e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7418 - loss: 5.0961e-04 - val_accuracy: 0.7603 - val_loss: 4.8758e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7415 - loss: 5.1037e-04 - val_accuracy: 0.7612 - val_loss: 4.9047e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7413 - loss: 5.1169e-04 - val_accuracy: 0.7606 - val_loss: 4.8477e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7415 - loss: 5.1298e-04 - val_accuracy: 0.7640 - val_loss: 4.8519e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7420 - loss: 5.1114e-04 - val_accuracy: 0.7657 - val_loss: 4.8001e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7441 - loss: 5.0631e-04 - val_accuracy: 0.7640 - val_loss: 4.8270e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7437 - loss: 5.0887e-04 - val_accuracy: 0.7636 - val_loss: 4.8192e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7440 - loss: 5.0567e-04 - val_accuracy: 0.7633 - val_loss: 4.8275e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7446 - loss: 5.0800e-04 - val_accuracy: 0.7627 - val_loss: 4.8261e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7441 - loss: 5.0770e-04 - val_accuracy: 0.7650 - val_loss: 4.8107e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7458 - loss: 5.0406e-04 - val_accuracy: 0.7631 - val_loss: 4.8485e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7454 - loss: 5.0411e-04 - val_accuracy: 0.7679 - val_loss: 4.7839e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7457 - loss: 5.0194e-04 - val_accuracy: 0.7662 - val_loss: 4.8190e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7467 - loss: 5.0284e-04 - val_accuracy: 0.7676 - val_loss: 4.8063e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7474 - loss: 5.0287e-04 - val_accuracy: 0.7625 - val_loss: 4.8324e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7461 - loss: 5.0215e-04 - val_accuracy: 0.7675 - val_loss: 4.7543e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7469 - loss: 5.0185e-04 - val_accuracy: 0.7659 - val_loss: 4.7922e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7466 - loss: 5.0188e-04 - val_accuracy: 0.7678 - val_loss: 4.7629e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7472 - loss: 5.0058e-04 - val_accuracy: 0.7646 - val_loss: 4.7846e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7459 - loss: 5.0194e-04 - val_accuracy: 0.7679 - val_loss: 4.7459e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7490 - loss: 4.9847e-04 - val_accuracy: 0.7646 - val_loss: 4.8477e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7472 - loss: 5.0094e-04 - val_accuracy: 0.7650 - val_loss: 4.7806e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7490 - loss: 4.9681e-04 - val_accuracy: 0.7669 - val_loss: 4.7708e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7489 - loss: 4.9824e-04 - val_accuracy: 0.7674 - val_loss: 4.7561e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7484 - loss: 4.9865e-04 - val_accuracy: 0.7669 - val_loss: 4.8082e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7491 - loss: 4.9721e-04 - val_accuracy: 0.7680 - val_loss: 4.7354e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7499 - loss: 4.9771e-04 - val_accuracy: 0.7683 - val_loss: 4.7760e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7500 - loss: 4.9658e-04 - val_accuracy: 0.7720 - val_loss: 4.7005e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.7495 - loss: 4.9752e-04 - val_accuracy: 0.7689 - val_loss: 4.7622e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7504 - loss: 4.9675e-04 - val_accuracy: 0.7696 - val_loss: 4.7462e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7504 - loss: 4.9449e-04 - val_accuracy: 0.7688 - val_loss: 4.7324e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7517 - loss: 4.9137e-04 - val_accuracy: 0.7698 - val_loss: 4.7368e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7514 - loss: 4.9425e-04 - val_accuracy: 0.7707 - val_loss: 4.7100e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7517 - loss: 4.9371e-04 - val_accuracy: 0.7705 - val_loss: 4.7514e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7524 - loss: 4.9305e-04 - val_accuracy: 0.7699 - val_loss: 4.7543e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7515 - loss: 4.9323e-04 - val_accuracy: 0.7695 - val_loss: 4.7270e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7526 - loss: 4.9152e-04 - val_accuracy: 0.7709 - val_loss: 4.7075e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7528 - loss: 4.9245e-04 - val_accuracy: 0.7647 - val_loss: 4.7639e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7524 - loss: 4.9205e-04 - val_accuracy: 0.7707 - val_loss: 4.7328e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7535 - loss: 4.9033e-04 - val_accuracy: 0.7721 - val_loss: 4.6846e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7523 - loss: 4.9076e-04 - val_accuracy: 0.7708 - val_loss: 4.7045e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7538 - loss: 4.8850e-04 - val_accuracy: 0.7707 - val_loss: 4.7400e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7532 - loss: 4.9227e-04 - val_accuracy: 0.7703 - val_loss: 4.7609e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7540 - loss: 4.8956e-04 - val_accuracy: 0.7706 - val_loss: 4.7270e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7543 - loss: 4.8674e-04 - val_accuracy: 0.7743 - val_loss: 4.6549e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7537 - loss: 4.8576e-04 - val_accuracy: 0.7727 - val_loss: 4.6659e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7538 - loss: 4.8783e-04 - val_accuracy: 0.7768 - val_loss: 4.6429e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7553 - loss: 4.8645e-04 - val_accuracy: 0.7725 - val_loss: 4.6857e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m1073/1073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.7544 - loss: 4.8788e-04 - val_accuracy: 0.7717 - val_loss: 4.7107e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f92f67eb250>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformerMatcher.train_model(\n",
    "    epochs=100,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "    batch_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.save_model(MODEL_DIR + \"model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

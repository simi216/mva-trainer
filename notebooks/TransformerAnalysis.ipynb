{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f7c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Ensure the parent directory is in the path\n",
    "\n",
    "import core.assingment as Models\n",
    "from core.DataLoader import DataPreprocessor, DataConfig\n",
    "import core\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "MAX_JETS = 6\n",
    "PLOTS_DIR = f\"plots/\"\n",
    "import os\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "\n",
    "config = DataConfig(jet_features=[\"ordered_jet_pt\",\"ordered_jet_eta\", \"ordered_jet_phi\",\"ordered_jet_e\",\"ordered_jet_b_tag\"], \n",
    "                                lepton_features=[\"lep_pt\", \"lep_eta\", \"lep_phi\", \"lep_e\"],\n",
    "                                jet_truth_label=\"ordered_event_jet_truth_idx\", \n",
    "                                lepton_truth_label=\"event_lepton_truth_idx\", \n",
    "                                global_features = [\"met_met_NOSYS\",\"met_phi_NOSYS\"], \n",
    "                                max_leptons=2, \n",
    "                                max_jets = MAX_JETS, \n",
    "                                non_training_features =[\"truth_ttbar_mass\", \"truth_ttbar_pt\", \"N_jets\"], \n",
    "                                event_weight=\"weight_mc_NOSYS\")\n",
    "\n",
    "DataProcessor = DataPreprocessor(config)\n",
    "DataProcessor.load_data(\"../../DATA/full_training.root\", \"reco\", max_events=1000000)\n",
    "DataProcessor.normalise_data()\n",
    "X_train,y_train, X_val, y_val = DataProcessor.split_data(test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8dce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"FeatureConcatTransformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"FeatureConcatTransformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ global_inputs       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lep_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,919</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GenerateMask</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ jet_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,472</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_output_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,440</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>)               │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_assignment_pro… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_output_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TemporalSoftmax</span>)   │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ global_inputs       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ global_inputs[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lep_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m15\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ jet_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ repeat_vector_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_embedding (\u001b[38;5;33mMLP\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │      \u001b[38;5;34m3,919\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGenerateMask\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ jet_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m33,472\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_output_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │      \u001b[38;5;34m1,440\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mMLP\u001b[0m)               │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_assignment_pro… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_output_embed… │\n",
       "│ (\u001b[38;5;33mTemporalSoftmax\u001b[0m)   │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,191</span> (805.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,191\u001b[0m (805.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,191</span> (805.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m206,191\u001b[0m (805.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.FeatureConcatTransformer(config, name=\"Transformer\")\n",
    "\n",
    "TransformerMatcher.build_model(\n",
    "    num_heads=8,\n",
    "    hidden_dim=64,\n",
    "    num_layers=6,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "TransformerMatcher.compile_model(\n",
    "    loss = core.utils.AssignmentLoss(lambda_excl=0), optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4), metrics=[core.utils.AssignmentAccuracy()]\n",
    ")\n",
    "TransformerMatcher.model.summary()\n",
    "#TransformerMatcher.load_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adc6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 31ms/step - assignment_accuracy: 0.2641 - loss: 0.5600 - val_assignment_accuracy: 0.6163 - val_loss: 0.3860\n",
      "Epoch 2/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 32ms/step - assignment_accuracy: 0.5749 - loss: 0.4122 - val_assignment_accuracy: 0.6617 - val_loss: 0.3552\n",
      "Epoch 3/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 33ms/step - assignment_accuracy: 0.6175 - loss: 0.3872 - val_assignment_accuracy: 0.6649 - val_loss: 0.3430\n",
      "Epoch 4/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 34ms/step - assignment_accuracy: 0.6335 - loss: 0.3733 - val_assignment_accuracy: 0.6753 - val_loss: 0.3339\n",
      "Epoch 5/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 36ms/step - assignment_accuracy: 0.6452 - loss: 0.3663 - val_assignment_accuracy: 0.6910 - val_loss: 0.3269\n",
      "Epoch 6/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 36ms/step - assignment_accuracy: 0.6549 - loss: 0.3574 - val_assignment_accuracy: 0.7030 - val_loss: 0.3138\n",
      "Epoch 7/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 36ms/step - assignment_accuracy: 0.6680 - loss: 0.3482 - val_assignment_accuracy: 0.7203 - val_loss: 0.3030\n",
      "Epoch 8/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 37ms/step - assignment_accuracy: 0.6802 - loss: 0.3379 - val_assignment_accuracy: 0.7234 - val_loss: 0.2933\n",
      "Epoch 9/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 38ms/step - assignment_accuracy: 0.6904 - loss: 0.3265 - val_assignment_accuracy: 0.7347 - val_loss: 0.2831\n",
      "Epoch 10/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 37ms/step - assignment_accuracy: 0.7000 - loss: 0.3176 - val_assignment_accuracy: 0.7400 - val_loss: 0.2766\n",
      "Epoch 11/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 40ms/step - assignment_accuracy: 0.7052 - loss: 0.3117 - val_assignment_accuracy: 0.7468 - val_loss: 0.2725\n",
      "Epoch 12/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 38ms/step - assignment_accuracy: 0.7107 - loss: 0.3064 - val_assignment_accuracy: 0.7490 - val_loss: 0.2693\n",
      "Epoch 13/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 40ms/step - assignment_accuracy: 0.7147 - loss: 0.3042 - val_assignment_accuracy: 0.7537 - val_loss: 0.2656\n",
      "Epoch 14/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 39ms/step - assignment_accuracy: 0.7189 - loss: 0.2986 - val_assignment_accuracy: 0.7538 - val_loss: 0.2644\n",
      "Epoch 15/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 39ms/step - assignment_accuracy: 0.7215 - loss: 0.2953 - val_assignment_accuracy: 0.7583 - val_loss: 0.2622\n",
      "Epoch 16/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 39ms/step - assignment_accuracy: 0.7246 - loss: 0.2930 - val_assignment_accuracy: 0.7557 - val_loss: 0.2617\n",
      "Epoch 17/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 41ms/step - assignment_accuracy: 0.7270 - loss: 0.2902 - val_assignment_accuracy: 0.7600 - val_loss: 0.2584\n",
      "Epoch 18/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 39ms/step - assignment_accuracy: 0.7279 - loss: 0.2881 - val_assignment_accuracy: 0.7612 - val_loss: 0.2587\n",
      "Epoch 19/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 39ms/step - assignment_accuracy: 0.7305 - loss: 0.2855 - val_assignment_accuracy: 0.7594 - val_loss: 0.2580\n",
      "Epoch 20/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 40ms/step - assignment_accuracy: 0.7334 - loss: 0.2843 - val_assignment_accuracy: 0.7609 - val_loss: 0.2572\n",
      "Epoch 21/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 41ms/step - assignment_accuracy: 0.7336 - loss: 0.2819 - val_assignment_accuracy: 0.7646 - val_loss: 0.2515\n",
      "Epoch 22/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 40ms/step - assignment_accuracy: 0.7363 - loss: 0.2807 - val_assignment_accuracy: 0.7594 - val_loss: 0.2559\n",
      "Epoch 23/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 37ms/step - assignment_accuracy: 0.7375 - loss: 0.2797 - val_assignment_accuracy: 0.7615 - val_loss: 0.2580\n",
      "Epoch 24/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 36ms/step - assignment_accuracy: 0.7386 - loss: 0.2765 - val_assignment_accuracy: 0.7659 - val_loss: 0.2520\n",
      "Epoch 25/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 37ms/step - assignment_accuracy: 0.7419 - loss: 0.2754 - val_assignment_accuracy: 0.7629 - val_loss: 0.2545\n",
      "Epoch 26/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 37ms/step - assignment_accuracy: 0.7425 - loss: 0.2747 - val_assignment_accuracy: 0.7673 - val_loss: 0.2517\n",
      "Epoch 27/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 37ms/step - assignment_accuracy: 0.7432 - loss: 0.2739 - val_assignment_accuracy: 0.7639 - val_loss: 0.2509\n",
      "Epoch 28/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 40ms/step - assignment_accuracy: 0.7436 - loss: 0.2729 - val_assignment_accuracy: 0.7668 - val_loss: 0.2506\n",
      "Epoch 29/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 40ms/step - assignment_accuracy: 0.7449 - loss: 0.2710 - val_assignment_accuracy: 0.7714 - val_loss: 0.2491\n",
      "Epoch 30/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 39ms/step - assignment_accuracy: 0.7462 - loss: 0.2694 - val_assignment_accuracy: 0.7653 - val_loss: 0.2534\n",
      "Epoch 31/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 37ms/step - assignment_accuracy: 0.7472 - loss: 0.2687 - val_assignment_accuracy: 0.7678 - val_loss: 0.2496\n",
      "Epoch 32/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 38ms/step - assignment_accuracy: 0.7457 - loss: 0.2692 - val_assignment_accuracy: 0.7675 - val_loss: 0.2501\n",
      "Epoch 33/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 38ms/step - assignment_accuracy: 0.7474 - loss: 0.2680 - val_assignment_accuracy: 0.7705 - val_loss: 0.2506\n",
      "Epoch 34/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 37ms/step - assignment_accuracy: 0.7487 - loss: 0.2679 - val_assignment_accuracy: 0.7744 - val_loss: 0.2464\n",
      "Epoch 35/50\n",
      "\u001b[1m5609/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 37ms/step - assignment_accuracy: 0.7498 - loss: 0.2663 - val_assignment_accuracy: 0.7688 - val_loss: 0.2521\n",
      "Epoch 36/50\n",
      "\u001b[1m5608/5609\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - assignment_accuracy: 0.7521 - loss: 0.2648"
     ]
    }
   ],
   "source": [
    "TransformerMatcher.train_model(epochs=50,\n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "                                batch_size=128,\n",
    "                                callbacks = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True, mode =\"min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.save_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = TransformerMatcher.predict_indices(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ConfusionMatrixDisplay.from_predictions(y_val[:,:,1].argmax(axis=-1),pred_val[:,:,1].argmax(axis=-1), normalize=\"true\", ax=ax)\n",
    "plt.savefig(PLOTS_DIR+\"/confusion_matrix_lepton.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d524bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(core)\n",
    "ml_eval = core.assingment.MLEvaluatorBase(TransformerMatcher, X_val, y_val)\n",
    "importances = ml_eval.compute_permutation_importance(num_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_eval.plot_feature_importance(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499be253",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.export_to_onnx(\"Transformer_Assignment.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91c521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "onnx_model = onnx.load(\"Transformer_Assignment.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "ort_session = ort.InferenceSession(\"Transformer_Assignment.onnx\")\n",
    "flatted_inputs = np.concatenate([X_val['jet'].reshape(X_val['jet'].shape[0], -1), X_val['lepton'].reshape(X_val['lepton'].shape[0], -1), X_val['global'].reshape(X_val[\"global\"].shape[0],-1)], axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e31ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ort_session.run(None, {\"flat_input\": flatted_inputs})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_val[:,:,0].argmax(axis=-1),outputs[:,:,0].argmax(axis=-1), normalize=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff42a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

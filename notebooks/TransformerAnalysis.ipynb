{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f7c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 16:08:02.062427: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-02 16:08:02.063268: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-02 16:08:02.067110: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-02 16:08:02.076597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759414082.091873  271690 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759414082.096211  271690 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759414082.109906  271690 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759414082.109928  271690 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759414082.109931  271690 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759414082.109934  271690 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-02 16:08:02.114726: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Ensure the parent directory is in the path\n",
    "\n",
    "import core.assingment as Models\n",
    "from core.DataLoader import DataPreprocessor, DataConfig\n",
    "import core\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "MAX_JETS = 6\n",
    "PLOTS_DIR = f\"plots/\"\n",
    "import os\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "\n",
    "config = DataConfig(jet_features=[\"ordered_jet_pt\", \"ordered_jet_e\", \"ordered_jet_phi\", \"ordered_jet_eta\", \"ordered_jet_b_tag\", \"dR_l1j\", \"dR_l2j\", \"m_l1j\", \"m_l2j\"], \n",
    "                                lepton_features=[\"lep_pt\",\"lep_e\", \"lep_eta\", \"lep_phi\"],\n",
    "                                jet_truth_label=\"ordered_event_jet_truth_idx\", \n",
    "                                lepton_truth_label=\"event_lepton_truth_idx\", \n",
    "                                global_features = [\"met_met_NOSYS\",\"met_phi_NOSYS\"], \n",
    "                                max_leptons=2, \n",
    "                                max_jets = MAX_JETS, \n",
    "                                non_training_features =[\"truth_ttbar_mass\", \"truth_ttbar_pt\", \"N_jets\"], \n",
    "                                event_weight=\"weight_mc_NOSYS\")\n",
    "\n",
    "DataProcessor = DataPreprocessor(config)\n",
    "DataProcessor.load_data(\"/data/dust/group/atlas/ttreco/full_training.root\", \"reco\", max_events=1000000)\n",
    "DataProcessor.normalise_data()\n",
    "X_train,y_train, X_val, y_val = DataProcessor.split_data(test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d8dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 16:08:46.942312: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"FeatureConcatTransformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"FeatureConcatTransformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ global_inputs       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lep_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_inputs          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,902</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_mask            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GenerateMask</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,544</span> │ jet_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,544</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,544</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,544</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttentionBloc…</span> │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_output_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">473</span> │ self_attention_b… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLP</span>)               │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_assignment_pro… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ jet_output_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TemporalSoftmax</span>)   │                   │            │ jet_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ global_inputs       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lep_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ global_inputs[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lep_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_inputs          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m9\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m19\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ jet_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ repeat_vector_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_embedding (\u001b[38;5;33mMLP\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m1,902\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_mask            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGenerateMask\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m8,544\u001b[0m │ jet_embedding[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m8,544\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m8,544\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_blo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m8,544\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mSelfAttentionBloc…\u001b[0m │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_output_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │        \u001b[38;5;34m473\u001b[0m │ self_attention_b… │\n",
       "│ (\u001b[38;5;33mMLP\u001b[0m)               │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jet_assignment_pro… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ jet_output_embed… │\n",
       "│ (\u001b[38;5;33mTemporalSoftmax\u001b[0m)   │                   │            │ jet_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,551</span> (142.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,551\u001b[0m (142.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,551</span> (142.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,551\u001b[0m (142.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.FeatureConcatTransformer(config, name=\"Transformer\")\n",
    "\n",
    "TransformerMatcher.build_model(\n",
    "    num_heads=8,\n",
    "    hidden_dim=32,\n",
    "    num_layers=4,\n",
    "    dropout_rate=0\n",
    ")\n",
    "TransformerMatcher.compile_model(\n",
    "    loss = core.utils.AssignmentLoss(lambda_excl=5), optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-5), metrics=[core.utils.AssignmentAccuracy()]\n",
    ")\n",
    "TransformerMatcher.model.summary()\n",
    "#TransformerMatcher.load_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adc6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 132ms/step - assignment_accuracy: 0.4842 - loss: 0.4978 - val_assignment_accuracy: 0.6809 - val_loss: 0.3359\n",
      "Epoch 2/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 142ms/step - assignment_accuracy: 0.6946 - loss: 0.3186 - val_assignment_accuracy: 0.7294 - val_loss: 0.2732\n",
      "Epoch 3/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 129ms/step - assignment_accuracy: 0.7376 - loss: 0.2687 - val_assignment_accuracy: 0.7574 - val_loss: 0.2518\n",
      "Epoch 4/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 130ms/step - assignment_accuracy: 0.7584 - loss: 0.2501 - val_assignment_accuracy: 0.7661 - val_loss: 0.2421\n",
      "Epoch 5/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 133ms/step - assignment_accuracy: 0.7678 - loss: 0.2428 - val_assignment_accuracy: 0.7736 - val_loss: 0.2360\n",
      "Epoch 6/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 126ms/step - assignment_accuracy: 0.7741 - loss: 0.2361 - val_assignment_accuracy: 0.7802 - val_loss: 0.2323\n",
      "Epoch 7/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 129ms/step - assignment_accuracy: 0.7783 - loss: 0.2336 - val_assignment_accuracy: 0.7844 - val_loss: 0.2296\n",
      "Epoch 8/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 127ms/step - assignment_accuracy: 0.7821 - loss: 0.2282 - val_assignment_accuracy: 0.7852 - val_loss: 0.2282\n",
      "Epoch 9/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 127ms/step - assignment_accuracy: 0.7841 - loss: 0.2277 - val_assignment_accuracy: 0.7874 - val_loss: 0.2252\n",
      "Epoch 10/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 127ms/step - assignment_accuracy: 0.7872 - loss: 0.2254 - val_assignment_accuracy: 0.7904 - val_loss: 0.2241\n",
      "Epoch 11/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 126ms/step - assignment_accuracy: 0.7882 - loss: 0.2237 - val_assignment_accuracy: 0.7910 - val_loss: 0.2229\n",
      "Epoch 12/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 139ms/step - assignment_accuracy: 0.7913 - loss: 0.2216 - val_assignment_accuracy: 0.7939 - val_loss: 0.2221\n",
      "Epoch 13/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 123ms/step - assignment_accuracy: 0.7901 - loss: 0.2223 - val_assignment_accuracy: 0.7930 - val_loss: 0.2208\n",
      "Epoch 14/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 125ms/step - assignment_accuracy: 0.7925 - loss: 0.2208 - val_assignment_accuracy: 0.7936 - val_loss: 0.2213\n",
      "Epoch 15/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 127ms/step - assignment_accuracy: 0.7922 - loss: 0.2205 - val_assignment_accuracy: 0.7932 - val_loss: 0.2198\n",
      "Epoch 16/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 136ms/step - assignment_accuracy: 0.7937 - loss: 0.2207 - val_assignment_accuracy: 0.7960 - val_loss: 0.2199\n",
      "Epoch 17/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 147ms/step - assignment_accuracy: 0.7944 - loss: 0.2179 - val_assignment_accuracy: 0.7949 - val_loss: 0.2189\n",
      "Epoch 18/30\n",
      "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - assignment_accuracy: 0.7942 - loss: 0.2175"
     ]
    }
   ],
   "source": [
    "TransformerMatcher.train_model(epochs=30,\n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "                                batch_size=512,\n",
    "                                callbacks = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True, mode =\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.save_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = TransformerMatcher.predict_indices(X_val, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205e3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(y_val[:,:,0].argmax(axis=-1),pred_val[:,:,0].argmax(axis=-1), normalize=\"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d524bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(core)\n",
    "ml_eval = core.assingment.MLEvaluatorBase(TransformerMatcher, X_val, y_val)\n",
    "importances = ml_eval.compute_permutation_importance(num_repeats=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_eval.plot_feature_importance(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8c18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # Ensure the parent directory is in the path\n",
    "\n",
    "import core.assignment_models as Models\n",
    "from core.DataLoader import DataPreprocessor, DataConfig, LoadConfig\n",
    "import core\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MAX_JETS = 6\n",
    "\n",
    "PLOTS_DIR = f\"plots/\"\n",
    "import os\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "    os.makedirs(PLOTS_DIR)\n",
    "\n",
    "load_config = LoadConfig(\n",
    "    jet_features=[\n",
    "        \"ordered_jet_pt\",\n",
    "        \"ordered_jet_eta\",\n",
    "        \"ordered_jet_phi\",\n",
    "        \"ordered_jet_e\",\n",
    "        \"ordered_jet_b_tag\",\n",
    "    ],\n",
    "    lepton_features=[\"lep_pt\", \"lep_eta\", \"lep_phi\", \"lep_e\"],\n",
    "    jet_truth_label=\"ordered_event_jet_truth_idx\",\n",
    "    lepton_truth_label=\"event_lepton_truth_idx\",\n",
    "    met_features=[\"met_met_NOSYS\", \"met_phi_NOSYS\"],\n",
    "    max_leptons=2,\n",
    "    max_jets=MAX_JETS,\n",
    "    non_training_features=[\"truth_ttbar_mass\", \"truth_ttbar_pt\", \"N_jets\"],\n",
    "    event_weight=\"weight_mc_NOSYS\",\n",
    ")\n",
    "\n",
    "DataProcessor = DataPreprocessor(load_config)\n",
    "DataProcessor.load_data(\n",
    "    \"../../data/full_training.root\", \"reco\", max_events=1000000\n",
    ")\n",
    "X_train, y_train, X_val, y_val = DataProcessor.split_data(\n",
    "    test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "data_config = load_config.to_data_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "with uproot.open(\"../../data/full_training.root\") as f:\n",
    "    tree = f[\"reco\"]\n",
    "    keys = tree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(key) for key in keys if \"nu\" in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Models)\n",
    "reload(core)\n",
    "TransformerMatcher = Models.FeatureConcatTransformer(data_config, name=\"Transformer\")\n",
    "\n",
    "TransformerMatcher.build_model(\n",
    "    num_heads=8,\n",
    "    hidden_dim=64,\n",
    "    num_layers=6,\n",
    "    dropout_rate=0.1,\n",
    "    input_as_four_vector=True,\n",
    ")\n",
    "\n",
    "TransformerMatcher.adapt_normalization_layers(X_train)\n",
    "\n",
    "TransformerMatcher.compile_model(\n",
    "    loss = core.utils.AssignmentLoss(lambda_excl=0), optimizer=keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4), metrics=[core.utils.AssignmentAccuracy()]\n",
    ")\n",
    "TransformerMatcher.model.summary()\n",
    "TransformerMatcher.load_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.train_model(epochs=30,\n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train,\n",
    "                                sample_weights=core.utils.compute_sample_weights(X_train, y_train),\n",
    "                                batch_size=1028,\n",
    "                                callbacks = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=50, restore_best_weights=True, mode =\"min\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.save_model(\"Transformer_Assignment.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(core)\n",
    "ml_eval = core.reconstruction.MLEvaluator(TransformerMatcher, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_eval.plot_feature_importance(num_repeats=1)\n",
    "#ml_eval.plot_training_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TransformerMatcher.export_to_onnx(\"Transformer_Assignment.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "onnx_model = onnx.load(\"Transformer_Assignment.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "ort_session = ort.InferenceSession(\"Transformer_Assignment.onnx\")\n",
    "flatted_inputs = np.concatenate([X_val['jet'].reshape(X_val['jet'].shape[0], -1), X_val['lepton'].reshape(X_val['lepton'].shape[0], -1), X_val['met'].reshape(X_val[\"met\"].shape[0],-1)], axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ort_session.run(None, {\"flat_input\": flatted_inputs})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session.run(None, {\"flat_input\": flatted_inputs})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"Transformer_Assignment.onnx\")\n",
    "print([inp.name for inp in model.graph.input])\n",
    "print([out.name for out in model.graph.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.assignment_models as BaselineMethods\n",
    "import core.reconstruction.Evaluation as Evaluation\n",
    "reload(Evaluation)\n",
    "reload(BaselineMethods)\n",
    "delta_r_assigner = BaselineMethods.DeltaRAssigner(data_config, name=r\"$\\Delta R$-Assignment\")\n",
    "invariant_mass_assigner = BaselineMethods.LeptonJetMassAssigner(data_config, name = r\"$m(\\ell, j)$-Assignment\")\n",
    "\n",
    "evaluator = Evaluation.ReconstructionEvaluator([delta_r_assigner,invariant_mass_assigner,TransformerMatcher], X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_binned_accuracy(feature_data_type='non_training', feature_name='truth_ttbar_mass', xlims = (340e3,800e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_confusion_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.plot_all_accuracies()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
